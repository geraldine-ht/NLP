{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-project-Joly-Houatra.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "774d188d80b94e5dacb131161a3bec20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f169c4fdae97400983c160d7223bda99",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0ba10e3b2d1476092d7ae85f63813ff",
              "IPY_MODEL_720067f12c32467f8158ebcabfbe5c53"
            ]
          }
        },
        "f169c4fdae97400983c160d7223bda99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0ba10e3b2d1476092d7ae85f63813ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fbc9c74f27bd4f03afa40f2f7fbcda55",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_842a5658a4164ea8a83047f121cf02c0"
          }
        },
        "720067f12c32467f8158ebcabfbe5c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6318e50072324ea99973c3828a3ba81d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [26:27&lt;00:00, 278kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0bebf503c56942c995a9bd59af3953aa"
          }
        },
        "fbc9c74f27bd4f03afa40f2f7fbcda55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "842a5658a4164ea8a83047f121cf02c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6318e50072324ea99973c3828a3ba81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0bebf503c56942c995a9bd59af3953aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3516e0c0fab4e189848970206e57af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3e0744cfa16c4e57a977e79dd8486a15",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6c5b5529160647e7a3ce64c2055c6e07",
              "IPY_MODEL_9afd6f006e4544589ad8fb786e3a014c"
            ]
          }
        },
        "3e0744cfa16c4e57a977e79dd8486a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c5b5529160647e7a3ce64c2055c6e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_72e5844ad30140a1aaa5691c212662ba",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a9daed2179b4e388ab96460c459b347"
          }
        },
        "9afd6f006e4544589ad8fb786e3a014c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fab3d5480ab74d7cbc756737e4edd319",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 258kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f2a571c46194b29bae7cfbe632b5684"
          }
        },
        "72e5844ad30140a1aaa5691c212662ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a9daed2179b4e388ab96460c459b347": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fab3d5480ab74d7cbc756737e4edd319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f2a571c46194b29bae7cfbe632b5684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geraldine-ht/NLP/blob/master/NLP_project_Joly_Houatra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNlurWUqMmVW",
        "colab_type": "text"
      },
      "source": [
        "#  Projet NLP - ENSAE 2019/2020\n",
        "\n",
        "Houatra Géraldine - Joly Benjamin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vArHFTF5M02k",
        "colab_type": "text"
      },
      "source": [
        "Dans ce notebook, nous voulons réaliser une classification de sentiments sur des commentaires d'articles du New York Times. Nous voulons voir la corrélation entre le sentiment porté par un titre d'article et les sentiments véhiculés par les commentaires associés."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ9zzWlVPd5Z",
        "colab_type": "text"
      },
      "source": [
        "Schéma illustrant la réalisation de notre projet à travers ce Colab (en bleu le nettoyage, en orange la labellisation et en vert le modèle BERT :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jHGbV2nNM-e",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?id=1F4JU351gSgfSl96kfoqszGIVlLzqlQFJ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD9KSHJcMxcP",
        "colab_type": "text"
      },
      "source": [
        "# Modules et Bibliothèques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z6kPEpCXpAZ",
        "colab_type": "code",
        "outputId": "b1f03843-ac2c-4cd3-aca2-44f7026fe8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Modules et Bibliothèques utilisées\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import log\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import plot, show, savefig, xlim, figure, ylim, legend, boxplot, setp, axes\n",
        "from scipy import stats\n",
        "from pandas import plotting\n",
        "from sklearn.model_selection import KFold,train_test_split\n",
        "from sklearn import model_selection\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats.stats import pearsonr\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from IPython.display import Math,display, HTML, Image, Latex, SVG\n",
        "\n",
        "%matplotlib inline "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd2Y0VuU08O2",
        "colab_type": "text"
      },
      "source": [
        "# Importation des bases de données\n",
        "\n",
        "On dispose de 3 bases de données :\n",
        "\n",
        "*   Trump_Articles : contient les titres et l'ID des articles traitant de Trump en mars 2018\n",
        "*   Trump_Comments : contient les commentaires et l'ID de l'article en lien de mars 2018, concernant les article portant sur Trump\n",
        "*   Comment_March_2018 : contient les commentaires et l'ID de l'article en lien de mars 2018, concernant les article NE portant PAS sur Trump\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoHixcQAXvQN",
        "colab_type": "code",
        "outputId": "11c331cd-5b8b-4af4-bec3-6bf28ba34aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "# telechargement de la BDD \"Articles_Trump\"\n",
        "!wget -O Trump_Articles.csv https://drive.google.com/uc?id=1EEPVrd_XV6lcS7zwyjKJ2t7r056SU92B\n",
        "Trump_Articles = pd.read_csv('/content/Trump_Articles.csv', delimiter=';')\n",
        "Trump_Articles = Trump_Articles[['headline','articleID']]\n",
        "Trump_Articles.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-12 12:24:38--  https://drive.google.com/uc?id=1EEPVrd_XV6lcS7zwyjKJ2t7r056SU92B\n",
            "Resolving drive.google.com (drive.google.com)... 172.253.118.101, 172.253.118.138, 172.253.118.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.253.118.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/45vicht2fhvnsl72o1uq9si0qqpoak0g/1586694225000/08369696792954202122/*/1EEPVrd_XV6lcS7zwyjKJ2t7r056SU92B [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-04-12 12:24:39--  https://doc-10-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/45vicht2fhvnsl72o1uq9si0qqpoak0g/1586694225000/08369696792954202122/*/1EEPVrd_XV6lcS7zwyjKJ2t7r056SU92B\n",
            "Resolving doc-10-94-docs.googleusercontent.com (doc-10-94-docs.googleusercontent.com)... 172.217.194.132, 2404:6800:4003:c04::84\n",
            "Connecting to doc-10-94-docs.googleusercontent.com (doc-10-94-docs.googleusercontent.com)|172.217.194.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1226854 (1.2M) [text/csv]\n",
            "Saving to: ‘Trump_Articles.csv’\n",
            "\n",
            "Trump_Articles.csv  100%[===================>]   1.17M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2020-04-12 12:24:40 (177 MB/s) - ‘Trump_Articles.csv’ saved [1226854/1226854]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>articleID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>G.O.P. Leadership Poised to Topple Obama’s Pi...</td>\n",
              "      <td>58691a5795d0e039260788b9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sprint and Mr. Trump’s Fictional Jobs</td>\n",
              "      <td>586a0d8795d0e039260789b3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>America  Becomes a Stan</td>\n",
              "      <td>586a0d8795d0e039260789b6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mr. Trump, Bureaucracy Apprentice</td>\n",
              "      <td>586b037e95d0e03926078af5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lessons From the Tea Party</td>\n",
              "      <td>586b10be95d0e03926078b11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline                 articleID\n",
              "0   G.O.P. Leadership Poised to Topple Obama’s Pi...  58691a5795d0e039260788b9\n",
              "1              Sprint and Mr. Trump’s Fictional Jobs  586a0d8795d0e039260789b3\n",
              "2                            America  Becomes a Stan  586a0d8795d0e039260789b6\n",
              "3                  Mr. Trump, Bureaucracy Apprentice  586b037e95d0e03926078af5\n",
              "4                         Lessons From the Tea Party  586b10be95d0e03926078b11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MXFbKXfZAsk",
        "colab_type": "code",
        "outputId": "4b10c0ca-56c2-4aee-e21a-0894aacd05cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "# telechargement de la BDD \"Comments_Trump\" réduite et focalisée sur les commentaire\n",
        "!wget -O Trump_Comments.csv https://drive.google.com/uc?id=1iXeiDVvTZAbkIff8hWquHtXNw8sRdoLB\n",
        "Trump_Comments = pd.read_csv('/content/Trump_Comments.csv', delimiter=';')\n",
        "Trump_Comments.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-12 12:24:43--  https://drive.google.com/uc?id=1iXeiDVvTZAbkIff8hWquHtXNw8sRdoLB\n",
            "Resolving drive.google.com (drive.google.com)... 172.253.118.101, 172.253.118.138, 172.253.118.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.253.118.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0s-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/gcm9cj0gceenqcteh18eg1ftc10320st/1586694225000/08369696792954202122/*/1iXeiDVvTZAbkIff8hWquHtXNw8sRdoLB [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-04-12 12:24:48--  https://doc-0s-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/gcm9cj0gceenqcteh18eg1ftc10320st/1586694225000/08369696792954202122/*/1iXeiDVvTZAbkIff8hWquHtXNw8sRdoLB\n",
            "Resolving doc-0s-94-docs.googleusercontent.com (doc-0s-94-docs.googleusercontent.com)... 172.217.194.132, 2404:6800:4003:c04::84\n",
            "Connecting to doc-0s-94-docs.googleusercontent.com (doc-0s-94-docs.googleusercontent.com)|172.217.194.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘Trump_Comments.csv’\n",
            "\n",
            "Trump_Comments.csv      [     <=>            ]  51.58M  25.1MB/s    in 2.1s    \n",
            "\n",
            "2020-04-12 12:24:50 (25.1 MB/s) - ‘Trump_Comments.csv’ saved [54082976]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commentBody</th>\n",
              "      <th>articleID</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oh, everybody is like that. A good fair honest...</td>\n",
              "      <td>5a9752a2410cf7000162e8ba</td>\n",
              "      <td>65046283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Trump will go down as the WORST PRESIDENT IN T...</td>\n",
              "      <td>5a9752a2410cf7000162e8ba</td>\n",
              "      <td>72717423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It is hard to imagine Trump as he is and has b...</td>\n",
              "      <td>5a9752a2410cf7000162e8ba</td>\n",
              "      <td>52585988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"None of this is remotely surprising anymore, ...</td>\n",
              "      <td>5a9752a2410cf7000162e8ba</td>\n",
              "      <td>1812066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'm not a doctor or a health professional but ...</td>\n",
              "      <td>5a9752a2410cf7000162e8ba</td>\n",
              "      <td>42087476</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         commentBody  ...    userID\n",
              "0  Oh, everybody is like that. A good fair honest...  ...  65046283\n",
              "1  Trump will go down as the WORST PRESIDENT IN T...  ...  72717423\n",
              "2  It is hard to imagine Trump as he is and has b...  ...  52585988\n",
              "3  \"None of this is remotely surprising anymore, ...  ...   1812066\n",
              "4  I'm not a doctor or a health professional but ...  ...  42087476\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLP5ISItX-RX",
        "colab_type": "code",
        "outputId": "91e8f43c-ad3c-40b4-97d4-b13319f1835c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "# telechargement de la BDD \"Comments_March_2018\" sans lien avec Trump\n",
        "!wget -O Comments_March_2018.csv https://drive.google.com/uc?id=13pQuetkRL8MUU-_s61T-jWYp9QYcF0qO\n",
        "Comments_March_2018 = pd.read_csv('/content/Comments_March_2018.csv', delimiter=';')\n",
        "Comments_March_2018.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-12 12:24:53--  https://drive.google.com/uc?id=13pQuetkRL8MUU-_s61T-jWYp9QYcF0qO\n",
            "Resolving drive.google.com (drive.google.com)... 172.253.118.100, 172.253.118.139, 172.253.118.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.253.118.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-08-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ur46sbug6sju974v1ogid1640a8q9gkr/1586694225000/08369696792954202122/*/13pQuetkRL8MUU-_s61T-jWYp9QYcF0qO [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-04-12 12:24:59--  https://doc-08-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ur46sbug6sju974v1ogid1640a8q9gkr/1586694225000/08369696792954202122/*/13pQuetkRL8MUU-_s61T-jWYp9QYcF0qO\n",
            "Resolving doc-08-94-docs.googleusercontent.com (doc-08-94-docs.googleusercontent.com)... 172.217.194.132, 2404:6800:4003:c04::84\n",
            "Connecting to doc-08-94-docs.googleusercontent.com (doc-08-94-docs.googleusercontent.com)|172.217.194.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘Comments_March_2018.csv’\n",
            "\n",
            "Comments_March_2018     [    <=>             ]  57.25M  22.6MB/s    in 2.5s    \n",
            "\n",
            "2020-04-12 12:25:03 (22.6 MB/s) - ‘Comments_March_2018.csv’ saved [60028503]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commentBody</th>\n",
              "      <th>articleID</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>If the choice is between mining for bitcoin - ...</td>\n",
              "      <td>5a974697410cf7000162e8a4</td>\n",
              "      <td>46903103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;br/&gt;To me, Bitcoin (et al) appears to be an e...</td>\n",
              "      <td>5a974697410cf7000162e8a4</td>\n",
              "      <td>82778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bitcoin is a pyramid scheme backed by nothing ...</td>\n",
              "      <td>5a974697410cf7000162e8a4</td>\n",
              "      <td>3013548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What does it cost in energy to dig up and refi...</td>\n",
              "      <td>5a974697410cf7000162e8a4</td>\n",
              "      <td>70245222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You forgot to mention stock buybacks.</td>\n",
              "      <td>5a974697410cf7000162e8a4</td>\n",
              "      <td>66424344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         commentBody  ...    userID\n",
              "0  If the choice is between mining for bitcoin - ...  ...  46903103\n",
              "1  <br/>To me, Bitcoin (et al) appears to be an e...  ...     82778\n",
              "2  Bitcoin is a pyramid scheme backed by nothing ...  ...   3013548\n",
              "3  What does it cost in energy to dig up and refi...  ...  70245222\n",
              "4             You forgot to mention stock buybacks.   ...  66424344\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4uzmagZ16SI",
        "colab_type": "text"
      },
      "source": [
        "# Création de nos ensembles de données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHMS_hc91jac",
        "colab_type": "text"
      },
      "source": [
        "##  Train & Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRl38lU22EJW",
        "colab_type": "code",
        "outputId": "dcf7a258-d401-4e23-dd29-61c00cf86d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# On extrait n=10 000 commentaires sur Trump pour l'ensemble de Train\n",
        "\n",
        "Train_Trump = Trump_Comments.sample(n=10000, random_state=1)\n",
        "Train_Trump"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commentBody</th>\n",
              "      <th>articleID</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>103106</th>\n",
              "      <td>Oh please build a wall. I think we should actu...</td>\n",
              "      <td>5a9d72fb410cf7000162f090</td>\n",
              "      <td>38611700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76834</th>\n",
              "      <td>The article raises so many issues that I think...</td>\n",
              "      <td>5ab4ff2447de81a901215ff1</td>\n",
              "      <td>2156318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27188</th>\n",
              "      <td>LOL. Repeat. Then sneer. And don't stop.&lt;br/&gt;I...</td>\n",
              "      <td>5aa265b447de81a90120c261</td>\n",
              "      <td>49780703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76416</th>\n",
              "      <td>I would hope she or anyone else who got close ...</td>\n",
              "      <td>5ab4701247de81a901215bec</td>\n",
              "      <td>14429551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7676</th>\n",
              "      <td>This is another short sided decision by a Pres...</td>\n",
              "      <td>5a996d3f410cf7000162ee6d</td>\n",
              "      <td>47124136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39255</th>\n",
              "      <td>It is very hard not to think that Tillerson ha...</td>\n",
              "      <td>5aa7c9c147de81a90120e141</td>\n",
              "      <td>79278717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108146</th>\n",
              "      <td>53% of the white women that voted, voted for t...</td>\n",
              "      <td>5aa5ccab47de81a90120d30c</td>\n",
              "      <td>56936950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111023</th>\n",
              "      <td>Of course the prospect of war is not to be tak...</td>\n",
              "      <td>5aaa40a747de81a901210447</td>\n",
              "      <td>72463355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19838</th>\n",
              "      <td>It is another ploy by Trump to destabilize the...</td>\n",
              "      <td>5aa031e947de81a90120b4de</td>\n",
              "      <td>35477595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7419</th>\n",
              "      <td>This is the same business acumen which flew th...</td>\n",
              "      <td>5a995c17410cf7000162ee2f</td>\n",
              "      <td>61145241</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              commentBody  ...    userID\n",
              "103106  Oh please build a wall. I think we should actu...  ...  38611700\n",
              "76834   The article raises so many issues that I think...  ...   2156318\n",
              "27188   LOL. Repeat. Then sneer. And don't stop.<br/>I...  ...  49780703\n",
              "76416   I would hope she or anyone else who got close ...  ...  14429551\n",
              "7676    This is another short sided decision by a Pres...  ...  47124136\n",
              "...                                                   ...  ...       ...\n",
              "39255   It is very hard not to think that Tillerson ha...  ...  79278717\n",
              "108146  53% of the white women that voted, voted for t...  ...  56936950\n",
              "111023  Of course the prospect of war is not to be tak...  ...  72463355\n",
              "19838   It is another ploy by Trump to destabilize the...  ...  35477595\n",
              "7419    This is the same business acumen which flew th...  ...  61145241\n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdA42HYV63oA",
        "colab_type": "code",
        "outputId": "4d261e87-e258-4435-d22a-130c8896df50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# on retire l'ensemble de Train de l'ensemble total pour ne pas les reprendre dans l'ensemble de Test\n",
        "\n",
        "print('Taille avant :', Trump_Comments.shape[0])\n",
        "print('Drop des lignes ...')\n",
        "Trump_Comments = Trump_Comments.drop(Train_Trump.index)\n",
        "print('Taille après :', Trump_Comments.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taille avant : 124421\n",
            "Drop des lignes ...\n",
            "Taille après : 114421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYJq5Zij3MNc",
        "colab_type": "code",
        "outputId": "d23aad56-a4dc-4ac8-9def-14c83bc3c7fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# On extrait n=40 000 commentaires NE portant PAS sur Trump pour l'ensemble de Train\n",
        "\n",
        "Train_NO_Trump = Comments_March_2018.sample(n=40000, random_state=1)\n",
        "Train_NO_Trump"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commentBody</th>\n",
              "      <th>articleID</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24135</th>\n",
              "      <td>Interesting not one mention of President Trump...</td>\n",
              "      <td>5aa29b1d47de81a90120c47d</td>\n",
              "      <td>73608530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85524</th>\n",
              "      <td>Did people stop using phones when telemarketer...</td>\n",
              "      <td>5abbd90447de81a901218c54</td>\n",
              "      <td>68935216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46375</th>\n",
              "      <td>I think the larger picture is that what happen...</td>\n",
              "      <td>5aabdbf547de81a901211412</td>\n",
              "      <td>1694096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11704</th>\n",
              "      <td>Ironic.  I thought we progressives are general...</td>\n",
              "      <td>5a9d563747de81a90120a1b7</td>\n",
              "      <td>54101121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3511</th>\n",
              "      <td>Ethics? What‚Äôs that.</td>\n",
              "      <td>5a9846bf410cf7000162eb4a</td>\n",
              "      <td>60205911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79464</th>\n",
              "      <td>I love music. I love listening to music. I lov...</td>\n",
              "      <td>5aba12a547de81a901217c97</td>\n",
              "      <td>59570791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10079</th>\n",
              "      <td>Whenever an area is defined by a technology by...</td>\n",
              "      <td>5a9c6b7f47de81a901209dc9</td>\n",
              "      <td>6374175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19663</th>\n",
              "      <td>I feel like everyone is misinterpreting the de...</td>\n",
              "      <td>5aa0305b47de81a90120b4d2</td>\n",
              "      <td>72822450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67608</th>\n",
              "      <td>A lot of good men have destroyed careers becau...</td>\n",
              "      <td>5ab4c21e47de81a901215ddc</td>\n",
              "      <td>53609548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54826</th>\n",
              "      <td>I was at dinner with some Air Force medical of...</td>\n",
              "      <td>5ab04eec47de81a901212e40</td>\n",
              "      <td>69062710</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             commentBody  ...    userID\n",
              "24135  Interesting not one mention of President Trump...  ...  73608530\n",
              "85524  Did people stop using phones when telemarketer...  ...  68935216\n",
              "46375  I think the larger picture is that what happen...  ...   1694096\n",
              "11704  Ironic.  I thought we progressives are general...  ...  54101121\n",
              "3511                              Ethics? What‚Äôs that.  ...  60205911\n",
              "...                                                  ...  ...       ...\n",
              "79464  I love music. I love listening to music. I lov...  ...  59570791\n",
              "10079  Whenever an area is defined by a technology by...  ...   6374175\n",
              "19663  I feel like everyone is misinterpreting the de...  ...  72822450\n",
              "67608  A lot of good men have destroyed careers becau...  ...  53609548\n",
              "54826  I was at dinner with some Air Force medical of...  ...  69062710\n",
              "\n",
              "[40000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMQnznX83jie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# On fusionne les deux ensemble de Train pour former notre ensemble de Train final contenant 50 000 commentaires :\n",
        "# 10 000 commentaires traitant d'un article sur Trump\n",
        "# 40 000 commentaires traitant d'un article NE portant PAS sur Trump\n",
        "\n",
        "Train = pd.concat([Train_NO_Trump, Train_Trump], ignore_index=True, sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY1vvFqs9xsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creation de l'ensemble de Validation de taille 10 000 à partir de l'ensemble de Train\n",
        "\n",
        "# on shuffle l'ensemble Train puis on extrait l'ensemble de validation\n",
        "Train = Train.sample(n=Train.shape[0], random_state=1)\n",
        "Validation = Train.sample(n=10000, random_state=1)\n",
        "# Actualisation de l'ensemble de Train pour avoir une taille de 40 000\n",
        "Train = Train.drop(Validation.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huFxJ2R6_dcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# On remet tous les ensembles sous forme de pd.DataFrama\n",
        "\n",
        "# Train\n",
        "Train = pd.DataFrame(Train)\n",
        "Train = Train.reset_index(drop=True)\n",
        "\n",
        "# Validation\n",
        "Validation = pd.DataFrame(Validation)\n",
        "Validation = Validation.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCmtH2rPL69Z",
        "colab_type": "code",
        "outputId": "3147beb0-dede-468c-8dca-93732f1e94b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "Train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commentBody</th>\n",
              "      <th>articleID</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Joe Biden, please!</td>\n",
              "      <td>5aad639447de81a901211e8b</td>\n",
              "      <td>12883090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I left teaching before I got in too deep.  The...</td>\n",
              "      <td>5ab842b947de81a9012170d2</td>\n",
              "      <td>45540664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Integration psychologically is only possible w...</td>\n",
              "      <td>5abd855c47de81a901219c1c</td>\n",
              "      <td>75948691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Love this...and her.  &lt;br/&gt;&lt;br/&gt;What a relief ...</td>\n",
              "      <td>5aaf7c2147de81a901212679</td>\n",
              "      <td>59977368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"There is an international community that occa...</td>\n",
              "      <td>5ab554d147de81a901216469</td>\n",
              "      <td>56137599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         commentBody  ...    userID\n",
              "0                                 Joe Biden, please!  ...  12883090\n",
              "1  I left teaching before I got in too deep.  The...  ...  45540664\n",
              "2  Integration psychologically is only possible w...  ...  75948691\n",
              "3  Love this...and her.  <br/><br/>What a relief ...  ...  59977368\n",
              "4  \"There is an international community that occa...  ...  56137599\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd8bDVktNCd1",
        "colab_type": "code",
        "outputId": "b8dc3bd9-0c86-4cfe-fbaf-440986b739aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "Validation.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commentBody</th>\n",
              "      <th>articleID</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why would people who don't have guns want to t...</td>\n",
              "      <td>5aaf86b847de81a9012126a9</td>\n",
              "      <td>82004583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ben Sasse. Nebraska Republican, is in Trump's ...</td>\n",
              "      <td>5a9d563747de81a90120a1b7</td>\n",
              "      <td>21208144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"the bulletproof private transports preferred ...</td>\n",
              "      <td>5aba19d147de81a901217cba</td>\n",
              "      <td>21694747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Reading the comments on here by Times readers ...</td>\n",
              "      <td>5a985b9a410cf7000162eb85</td>\n",
              "      <td>17788919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Let's not complicate this. Trump has also told...</td>\n",
              "      <td>5aa1143647de81a90120b853</td>\n",
              "      <td>14956507</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         commentBody  ...    userID\n",
              "0  Why would people who don't have guns want to t...  ...  82004583\n",
              "1  Ben Sasse. Nebraska Republican, is in Trump's ...  ...  21208144\n",
              "2  \"the bulletproof private transports preferred ...  ...  21694747\n",
              "3  Reading the comments on here by Times readers ...  ...  17788919\n",
              "4  Let's not complicate this. Trump has also told...  ...  14956507\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU6S1rdA1rG9",
        "colab_type": "text"
      },
      "source": [
        "##  Tests\n",
        "\n",
        "On définit deux ensembles de tests : les titres des articles concernant Trump d'un côté, des commentaires sur Trump de l'autre côté."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN1Q-r6Y5K12",
        "colab_type": "code",
        "outputId": "c1c9b289-7fcb-4f6b-d3c1-282f3fb1a368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# On extrait n=2111 (Trump_Articles.shape[0]) titres d'articles sur Trump pour l'ensemble de Test\n",
        "\n",
        "Test_Trump_articles = Trump_Articles.sample(n=Trump_Articles.shape[0], random_state=1)\n",
        "Test_Trump_articles = Test_Trump_articles.reset_index(drop=True)\n",
        "Test_Trump_articles.columns = ['commentBody', 'articleID']\n",
        "Test_Trump_articles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commentBody</th>\n",
              "      <th>articleID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Meager Support  for Blend of Policy in Replace...</td>\n",
              "      <td>58befc877c459f247962dbcb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Can This Presidency Be Saved?</td>\n",
              "      <td>589f6ff295d0e02474635d70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pence’s Presidential Pet</td>\n",
              "      <td>5892ec0795d0e0392607e28f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mike Pompeo Works the Hill</td>\n",
              "      <td>5acffed0068401528a2a86e8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trump Sees Trade Loss By Ignoring Key Sector</td>\n",
              "      <td>5aabeb5f47de81a90121150d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2106</th>\n",
              "      <td>The Guardrails Of Democracy</td>\n",
              "      <td>591580a67c459f24986df2f5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2107</th>\n",
              "      <td>The New Study That Shows Trumpcare’s Damage</td>\n",
              "      <td>590a886a7c459f24986dd989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>Oh Dear. The Trumps Keep Multiplying.</td>\n",
              "      <td>592fc07c7c459f24986e2c31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2109</th>\n",
              "      <td>Falwell’s New Role Could Aid His Own University</td>\n",
              "      <td>58924a9195d0e0392607e0fa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2110</th>\n",
              "      <td>Arms Deals Won’t Bring Peace</td>\n",
              "      <td>5927d7837c459f24986e1ce0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2111 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            commentBody                 articleID\n",
              "0     Meager Support  for Blend of Policy in Replace...  58befc877c459f247962dbcb\n",
              "1                         Can This Presidency Be Saved?  589f6ff295d0e02474635d70\n",
              "2                              Pence’s Presidential Pet  5892ec0795d0e0392607e28f\n",
              "3                            Mike Pompeo Works the Hill  5acffed0068401528a2a86e8\n",
              "4          Trump Sees Trade Loss By Ignoring Key Sector  5aabeb5f47de81a90121150d\n",
              "...                                                 ...                       ...\n",
              "2106                        The Guardrails Of Democracy  591580a67c459f24986df2f5\n",
              "2107        The New Study That Shows Trumpcare’s Damage  590a886a7c459f24986dd989\n",
              "2108              Oh Dear. The Trumps Keep Multiplying.  592fc07c7c459f24986e2c31\n",
              "2109    Falwell’s New Role Could Aid His Own University  58924a9195d0e0392607e0fa\n",
              "2110                       Arms Deals Won’t Bring Peace  5927d7837c459f24986e1ce0\n",
              "\n",
              "[2111 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn0Rg2-I6H_M",
        "colab_type": "code",
        "outputId": "fe6c051a-77fe-4421-d5de-a619a5fca163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# On extrait n=5 000 commentaires sur Trump pour l'ensemble de Test\n",
        "\n",
        "Test_Trump = Trump_Comments.sample(n=5000, random_state=1)\n",
        "Test_Trump = Test_Trump.reset_index(drop=True)\n",
        "Test_Trump"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commentBody</th>\n",
              "      <th>articleID</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bartolo -- \"Is there any evidence\"&lt;br/&gt;&lt;br/&gt;Ye...</td>\n",
              "      <td>5ab9862047de81a901217995</td>\n",
              "      <td>37674938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Reagan who didn't smoke advertised cigarettes ...</td>\n",
              "      <td>5ab136a147de81a901213555</td>\n",
              "      <td>62945206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Congress' time to \"wake up soon\" happened long...</td>\n",
              "      <td>5aaf7c1e47de81a901212671</td>\n",
              "      <td>59144840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As long as Republicans in Congress allow Trump...</td>\n",
              "      <td>5aac76e847de81a901211a5b</td>\n",
              "      <td>79969624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wow. I definitely won't be watching this show....</td>\n",
              "      <td>5aba502547de81a901217e5f</td>\n",
              "      <td>79070806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>The article reads as thought the VA merely pro...</td>\n",
              "      <td>5abd6a7647de81a901219b44</td>\n",
              "      <td>41558614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>Trump is simply repulsive.  He is everything w...</td>\n",
              "      <td>5aa43dbe47de81a90120cd88</td>\n",
              "      <td>23689673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>This is a good move. If steel manufacturing di...</td>\n",
              "      <td>5a981947410cf7000162eaa2</td>\n",
              "      <td>68501536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>Where is the reasoned and rational use of tari...</td>\n",
              "      <td>5aa031e947de81a90120b4de</td>\n",
              "      <td>56385081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>Unless and until we can see Donald Trump's per...</td>\n",
              "      <td>5a9d565e47de81a90120a23c</td>\n",
              "      <td>17374907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            commentBody  ...    userID\n",
              "0     Bartolo -- \"Is there any evidence\"<br/><br/>Ye...  ...  37674938\n",
              "1     Reagan who didn't smoke advertised cigarettes ...  ...  62945206\n",
              "2     Congress' time to \"wake up soon\" happened long...  ...  59144840\n",
              "3     As long as Republicans in Congress allow Trump...  ...  79969624\n",
              "4     Wow. I definitely won't be watching this show....  ...  79070806\n",
              "...                                                 ...  ...       ...\n",
              "4995  The article reads as thought the VA merely pro...  ...  41558614\n",
              "4996  Trump is simply repulsive.  He is everything w...  ...  23689673\n",
              "4997  This is a good move. If steel manufacturing di...  ...  68501536\n",
              "4998  Where is the reasoned and rational use of tari...  ...  56385081\n",
              "4999  Unless and until we can see Donald Trump's per...  ...  17374907\n",
              "\n",
              "[5000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyLChFL6SNyi",
        "colab_type": "text"
      },
      "source": [
        "Nous disposons maintenant de 4 ensembles : 2 pour l'apprentissage (Train et Validation) et deux pour les tests (Test_Trump sur les commentaires & Test_Trump_articles pour les titres des articles)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwZyWHRG_BM8",
        "colab_type": "text"
      },
      "source": [
        "# Nettoyage des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sTGk-X11StM",
        "colab_type": "text"
      },
      "source": [
        "##  Nettoyage avec fonctions personnelles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKz2grkJHjj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fonctions pour nettoyer le texte\n",
        "\n",
        "\n",
        "def remove_hashtags(tokens):\n",
        "  tokens = map(lambda x: x.replace('#', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_url(tokens):\n",
        "  tokens = filter(lambda x: \"http\" not in x, tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_html(tokens):\n",
        "  tokens = filter(lambda x: x[0]+x[-1] != '<>', tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_br1(tokens):\n",
        "  tokens = filter(lambda x: x.replace('<', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_br2(tokens):\n",
        "  tokens = filter(lambda x: x.replace('br/', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_br3(tokens):\n",
        "  tokens = filter(lambda x: x.replace('>', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_0(tokens):\n",
        "  tokens = map(lambda x: x.replace('0', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_1(tokens):\n",
        "  tokens = map(lambda x: x.replace('1', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_2(tokens):\n",
        "  tokens = map(lambda x: x.replace('2', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_3(tokens):\n",
        "  tokens = map(lambda x: x.replace('3', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_4(tokens):\n",
        "  tokens = map(lambda x: x.replace('4', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_5(tokens):\n",
        "  tokens = map(lambda x: x.replace('5', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_6(tokens):\n",
        "  tokens = map(lambda x: x.replace('6', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_7(tokens):\n",
        "  tokens = map(lambda x: x.replace('7', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_8(tokens):\n",
        "  tokens = map(lambda x: x.replace('8', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_9(tokens):\n",
        "  tokens = map(lambda x: x.replace('9', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_percent(tokens):\n",
        "  tokens = map(lambda x: x.replace('%', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_special_A(tokens):\n",
        "  tokens = map(lambda x: x.replace('Ä', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_special_U_1(tokens):\n",
        "  tokens = map(lambda x: x.replace('ú', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_special_U_2(tokens):\n",
        "  tokens = map(lambda x: x.replace('ù', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_special_I_1(tokens):\n",
        "  tokens = map(lambda x: x.replace('ì', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_special_1(tokens):\n",
        "  tokens = map(lambda x: x.replace('&', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_amp(tokens):\n",
        "  tokens = map(lambda x: x.replace('amp', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_gt(tokens):\n",
        "  tokens = map(lambda x: x.replace('gt', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_lt(tokens):\n",
        "  tokens = map(lambda x: x.replace('lt', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n",
        "def remove_punctuation_1(tokens):\n",
        "  tokens = map(lambda x: x.replace('-', ''), tokens)\n",
        "  return list(tokens)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVKUhetgHpQo",
        "colab_type": "code",
        "outputId": "ca080d24-b6fe-41c3-94f7-5a7b4ba4acbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Usage of Phrases and Phraser from gensim\n",
        "\n",
        "import nltk\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from nltk.tokenize import TreebankWordTokenizer, TweetTokenizer\n",
        "nltk.download('punkt')\n",
        "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def tokenize_url_hashtags(corpus):\n",
        "  tokenizer = TreebankWordTokenizer()  \n",
        "  # Life hack : treebank word tokenizer won't keep html code in one token.\n",
        "  # To preprocess economics news corpus, use tweettokenizer. \n",
        "  tokenized_sentences = []\n",
        "  tokenized_sentences_2 = []\n",
        "  for sample in tqdm(corpus):\n",
        "    # separating sentences\n",
        "    for sentence in sent_detector.tokenize(sample):\n",
        "      tokens = tokenizer.tokenize(sentence)\n",
        "      # cleaning\n",
        "      tokens = remove_html(tokens)\n",
        "      tokens = remove_url(tokens)\n",
        "      tokens = remove_hashtags(tokens)\n",
        "      tokens = remove_br1(tokens)\n",
        "      tokens = remove_br2(tokens)\n",
        "      tokens = remove_br3(tokens)\n",
        "      tokens = remove_0(tokens)\n",
        "      tokens = remove_1(tokens)\n",
        "      tokens = remove_2(tokens)\n",
        "      tokens = remove_3(tokens)\n",
        "      tokens = remove_4(tokens)\n",
        "      tokens = remove_5(tokens)\n",
        "      tokens = remove_6(tokens)\n",
        "      tokens = remove_7(tokens)\n",
        "      tokens = remove_8(tokens)\n",
        "      tokens = remove_9(tokens)\n",
        "      tokens = remove_percent(tokens)\n",
        "      tokens = remove_special_A(tokens)\n",
        "      tokens = remove_special_U_1(tokens)\n",
        "      tokens = remove_special_U_2(tokens)\n",
        "      tokens = remove_special_I_1(tokens)\n",
        "      tokens = remove_special_1(tokens)\n",
        "      tokens = remove_amp(tokens)\n",
        "      tokens = remove_punctuation_1(tokens)\n",
        "\n",
        "      tokens = list(map(lambda x: x.lower(), tokens))\n",
        "      tokenized_sentences_2.append(tokens)\n",
        "    tokenized_sentences.append(tokenized_sentences_2)\n",
        "    tokenized_sentences_2 = []\n",
        "  return tokenized_sentences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdDZxG-0IMHX",
        "colab_type": "code",
        "outputId": "048f98bb-fe5f-498d-8ceb-662cec535bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Application de la fonction de nettoyage (hors stopwords)\n",
        "\n",
        "Cleaned_Train_Temp = tokenize_url_hashtags(Train.commentBody.array)\n",
        "Cleaned_Test_Trump_articles_Temp = tokenize_url_hashtags(Test_Trump_articles.commentBody.array)\n",
        "Cleaned_Test_Trump_Temp = tokenize_url_hashtags(Test_Trump.commentBody.array)\n",
        "Cleaned_Validation_Temp = tokenize_url_hashtags(Validation.commentBody.array)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40000/40000 [00:40<00:00, 985.29it/s] \n",
            "100%|██████████| 2111/2111 [00:00<00:00, 7216.23it/s]\n",
            "100%|██████████| 5000/5000 [00:04<00:00, 1107.32it/s]\n",
            "100%|██████████| 10000/10000 [00:09<00:00, 1012.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4VWqxYqIxcW",
        "colab_type": "code",
        "outputId": "813512dc-c72c-4746-bef2-8a89dfd68e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Test sur l'ensemble Train\n",
        "\n",
        "print(Cleaned_Train_Temp[2])\n",
        "print('\\n')\n",
        "print(Train.commentBody[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['integration', 'psychologically', 'is', 'only', 'possible', 'when', 'understand', 'who', 'we', 'are', ',', 'where', 'we', 'come', 'from', 'and', 'where', 'we', 'are', 'going', '(', 'to', 'paraphrase', 'ella', 'baker', ')', '.'], ['evolution', 'provides', 'part', 'of', 'the', 'story', '.'], ['ivolution', '(', 'the', 'evolution', 'of', 'human', 'selfconsciousness', ')', 'completes', 'the', 'picture', '.'], ['there', 'will', 'always', 'be', 'fundamental', 'differences', 'between', 'humans', 'as', 'we', 'evolve', 'or', 'mature', 'in', 'selfconsciousness.', 'ewarriors', 'will', 'forever', 'be', 'conflicted', '.'], ['the', 'more', 'experienced', 'iwarriors', 'have', 'better', 'isight', '‚', 'they', 'can', 'see', 'more', 'of', 'the', 'big', 'picture', 'and', 'the', 'wholeness', 'and', 'sacredness', 'of', 'all', 'things', '.'], ['they', 'are', 'the', 'peace', 'makers', '.'], ['they', 'do', 'not', 'hate', 'because', 'they', 'understand', 'its', 'destructive', 'force', '.'], ['‚love', 'is', 'all', 'you', 'need‚', ',', 'is', 'a', 'song', 'often', 'sung', ',', 'but', 'to', 'possess', 'a', 'selfless', 'love', 'is', 'not', 'easy', 'to', 'come', 'by', '', 'it', 'is', 'the', 'treasure', 'that', 'can', 'only', 'be', 'purchased', 'by', 'experience', 'in', 'countless', 'previous', 'lives', '.'], ['he', 'jests', 'at', 'scars', 'that', 'never', 'felt', 'a', 'wound', '.'], ['shakespeare', '.'], ['when', 'virtuous', 'people', 'lead', '(', 'iwarriors', ')', 'only', 'then', 'can', 'we', 'feel', 'that', 'our', 'house', 'is', 'in', 'order', 'and', 'that', 'our', 'children', 'are', 'safe', '.']]\n",
            "\n",
            "\n",
            "Integration psychologically is only possible when understand who we are, where we come from and where we are going (to paraphrase Ella Baker).  Evolution provides part of the story. Ivolution (the evolution of human self-consciousness) completes the picture. There will always be fundamental differences between humans as we evolve or mature in self-consciousness.<br/>Ewarriors will forever be conflicted. The more experienced Iwarriors have better Isight ‚Äì they can see more of the big picture and the wholeness and sacredness of all things.  They are the peace makers. They do not hate because they understand its destructive force. ‚ÄúLove is all you need‚Äù, is a song often sung, but to possess a selfless love is not easy to come by  - it is the treasure that can only be purchased by experience in countless previous lives.  He jests at scars that never felt a wound. Shakespeare.  When virtuous people lead (Iwarriors) only then can we feel that our house is in order and that our children are safe. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMohl_qTPgRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# On reforme les commentaires nettoyés\n",
        "\n",
        "Cleaned_Train = []\n",
        "\n",
        "for i in range(len(Cleaned_Train_Temp)):\n",
        "  s = ''\n",
        "  for j in range(len(Cleaned_Train_Temp[i])):\n",
        "    for k in Cleaned_Train_Temp[i][j]:\n",
        "      s = s + ' ' + k\n",
        "  Cleaned_Train.append(s)\n",
        "\n",
        "\n",
        "Cleaned_Test_Trump = []\n",
        "\n",
        "for i in range(len(Cleaned_Test_Trump_Temp)):\n",
        "  s = ''\n",
        "  for j in range(len(Cleaned_Test_Trump_Temp[i])):\n",
        "    for k in Cleaned_Test_Trump_Temp[i][j]:\n",
        "      s = s + ' ' + k\n",
        "  Cleaned_Test_Trump.append(s)\n",
        "\n",
        "\n",
        "Cleaned_Test_Trump_articles = []\n",
        "\n",
        "for i in range(len(Cleaned_Test_Trump_articles_Temp)):\n",
        "  s = ''\n",
        "  for j in range(len(Cleaned_Test_Trump_articles_Temp[i])):\n",
        "    for k in Cleaned_Test_Trump_articles_Temp[i][j]:\n",
        "      s = s + ' ' + k\n",
        "  Cleaned_Test_Trump_articles.append(s)\n",
        "\n",
        "\n",
        "Cleaned_Validation = []\n",
        "\n",
        "for i in range(len(Cleaned_Validation_Temp)):\n",
        "  s = ''\n",
        "  for j in range(len(Cleaned_Validation_Temp[i])):\n",
        "    for k in Cleaned_Validation_Temp[i][j]:\n",
        "      s = s + ' ' + k\n",
        "  Cleaned_Validation.append(s)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55L4CZWoWRnw",
        "colab_type": "text"
      },
      "source": [
        "Les ensembles \"Cleaned_Train\", \"Cleaned_Test_Trump_articles\", \"Cleaned_Test_Trump\" et \"Cleaned_Validation\" contiennent nos données nettoyées AVEC les Stopwords. Ce sont ces ensembles que nous utiliserons avec BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT_QiRb25yue",
        "colab_type": "code",
        "outputId": "8b7a6ea8-9082-4e27-87bb-098d548021b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# Tests sur Train et Test_Trump pour vérifier le nettoyage et la reconstruction\n",
        "\n",
        "print(Cleaned_Train[2])\n",
        "print('\\n')\n",
        "print(Train.commentBody[2])\n",
        "print('\\n')\n",
        "print(Cleaned_Test_Trump[3])\n",
        "print('\\n')\n",
        "print(Test_Trump.commentBody[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " integration psychologically is only possible when understand who we are , where we come from and where we are going ( to paraphrase ella baker ) . evolution provides part of the story . ivolution ( the evolution of human selfconsciousness ) completes the picture . there will always be fundamental differences between humans as we evolve or mature in selfconsciousness. ewarriors will forever be conflicted . the more experienced iwarriors have better isight ‚ they can see more of the big picture and the wholeness and sacredness of all things . they are the peace makers . they do not hate because they understand its destructive force . ‚love is all you need‚ , is a song often sung , but to possess a selfless love is not easy to come by  it is the treasure that can only be purchased by experience in countless previous lives . he jests at scars that never felt a wound . shakespeare . when virtuous people lead ( iwarriors ) only then can we feel that our house is in order and that our children are safe .\n",
            "\n",
            "\n",
            "Integration psychologically is only possible when understand who we are, where we come from and where we are going (to paraphrase Ella Baker).  Evolution provides part of the story. Ivolution (the evolution of human self-consciousness) completes the picture. There will always be fundamental differences between humans as we evolve or mature in self-consciousness.<br/>Ewarriors will forever be conflicted. The more experienced Iwarriors have better Isight ‚Äì they can see more of the big picture and the wholeness and sacredness of all things.  They are the peace makers. They do not hate because they understand its destructive force. ‚ÄúLove is all you need‚Äù, is a song often sung, but to possess a selfless love is not easy to come by  - it is the treasure that can only be purchased by experience in countless previous lives.  He jests at scars that never felt a wound. Shakespeare.  When virtuous people lead (Iwarriors) only then can we feel that our house is in order and that our children are safe. \n",
            "\n",
            "\n",
            " as long as republicans in congress allow trump to run the country as his own personal video game that can delete people with the flick of a finger on the keyboard , we 're in trouble . so obvious that trump is attempting to thwart mueller 's investigation by impugning the credibility of mccabe and comey . donald trump aka dennis the menace . who 's running the country while trump watches cable news , tweets , and golfs ? his sole mission is to bath in the glow of media attention , and anybody who dares stain his image is toast .\n",
            "\n",
            "\n",
            "As long as Republicans in Congress allow Trump to run the country as his own personal video game that can delete people with the flick of a finger on the keyboard, we're in trouble. So obvious that Trump is attempting to thwart Mueller's investigation by impugning the credibility of McCabe and Comey. Donald Trump aka Dennis the Menace. Who's running the country while Trump watches cable news, tweets, and golfs? His sole mission is to bath in the glow of media attention, and anybody who dares stain his image is toast. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev99BMJn1bI4",
        "colab_type": "text"
      },
      "source": [
        "##  Nettoyage des Stopwords et de la ponctuation avec nltk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm2S2LUTP-_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# On retire les StopWords et la ponctuation\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from gensim.models import LdaModel\n",
        "from gensim import corpora\n",
        "import nltk\n",
        "from string import punctuation\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "\n",
        "def Remove_sw_ponct(texte):\n",
        "  nltk.download('stopwords')\n",
        "  en_stop = set(nltk.corpus.stopwords.words('english'))\n",
        "  to_be_removed = list(en_stop) + list(punctuation)\n",
        "\n",
        "\n",
        "  Cleaned_Text = texte.copy()\n",
        "  for i in range(len(texte)) :\n",
        "    text = Cleaned_Text[i]\n",
        "    text_tokens = word_tokenize(text)\n",
        "  \n",
        "    tokens_without_sw = [word for word in text_tokens if not word in to_be_removed]\n",
        "\n",
        "    Cleaned_Text[i] = tokens_without_sw\n",
        "  \n",
        "  # On reforme les commentaires nettoyés\n",
        "\n",
        "  Cleaned_Label = []\n",
        "\n",
        "  for i in range(len(Cleaned_Text)):\n",
        "    s = ''\n",
        "    for k in Cleaned_Text[i]:\n",
        "      s = s + ' ' + k\n",
        "    Cleaned_Label.append(s)\n",
        "\n",
        "  return(Cleaned_Label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0qkhYvCQVuz",
        "colab_type": "code",
        "outputId": "e25af2d7-70a9-4a39-e616-66c171514a90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "Train_label = Remove_sw_ponct(Cleaned_Train)\n",
        "Test_Trump_articles_label = Remove_sw_ponct(Cleaned_Test_Trump_articles)\n",
        "Test_Trump_label = Remove_sw_ponct(Cleaned_Test_Trump)\n",
        "Validation_label = Remove_sw_ponct(Cleaned_Validation)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruk_OSpiWoda",
        "colab_type": "text"
      },
      "source": [
        "Les ensembles \"Train_label\", \"Test_Trump_articles_label\", \"Test_Trump_label\" et \"Validation_label\" contiennent nos données nettoyées SANS les Stopwords. Ce sont ces ensembles que nous utiliserons pour labelliser nos données."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmLBBFCQSbrY",
        "colab_type": "code",
        "outputId": "274005c6-0dca-4203-b069-f948bcdf2799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# Tests sur Train et Test_Trump pour vérifier le nettoyage et la reconstruction\n",
        "# Les stopwords et la ponctuation ont été enlevés\n",
        "\n",
        "print(Train_label[2])\n",
        "print('\\n')\n",
        "print(Train.commentBody[2])\n",
        "print('\\n')\n",
        "print(Test_Trump_label[3])\n",
        "print('\\n')\n",
        "print(Test_Trump.commentBody[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " integration psychologically possible understand come going paraphrase ella baker evolution provides part story ivolution evolution human selfconsciousness completes picture always fundamental differences humans evolve mature selfconsciousness ewarriors forever conflicted experienced iwarriors better isight ‚ see big picture wholeness sacredness things peace makers hate understand destructive force ‚love need‚ song often sung possess selfless love easy come treasure purchased experience countless previous lives jests scars never felt wound shakespeare virtuous people lead iwarriors feel house order children safe\n",
            "\n",
            "\n",
            "Integration psychologically is only possible when understand who we are, where we come from and where we are going (to paraphrase Ella Baker).  Evolution provides part of the story. Ivolution (the evolution of human self-consciousness) completes the picture. There will always be fundamental differences between humans as we evolve or mature in self-consciousness.<br/>Ewarriors will forever be conflicted. The more experienced Iwarriors have better Isight ‚Äì they can see more of the big picture and the wholeness and sacredness of all things.  They are the peace makers. They do not hate because they understand its destructive force. ‚ÄúLove is all you need‚Äù, is a song often sung, but to possess a selfless love is not easy to come by  - it is the treasure that can only be purchased by experience in countless previous lives.  He jests at scars that never felt a wound. Shakespeare.  When virtuous people lead (Iwarriors) only then can we feel that our house is in order and that our children are safe. \n",
            "\n",
            "\n",
            " long republicans congress allow trump run country personal video game delete people flick finger keyboard 're trouble obvious trump attempting thwart mueller 's investigation impugning credibility mccabe comey donald trump aka dennis menace 's running country trump watches cable news tweets golfs sole mission bath glow media attention anybody dares stain image toast\n",
            "\n",
            "\n",
            "As long as Republicans in Congress allow Trump to run the country as his own personal video game that can delete people with the flick of a finger on the keyboard, we're in trouble. So obvious that Trump is attempting to thwart Mueller's investigation by impugning the credibility of McCabe and Comey. Donald Trump aka Dennis the Menace. Who's running the country while Trump watches cable news, tweets, and golfs? His sole mission is to bath in the glow of media attention, and anybody who dares stain his image is toast. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybFd5MdGVxqm",
        "colab_type": "text"
      },
      "source": [
        "# Labellisation avec le lexique AFINN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvFJLNEFV2N0",
        "colab_type": "code",
        "outputId": "f110212e-1f9a-4b5e-d00b-4b4b1be8b751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# On installe le lexique AFINN\n",
        "!pip install afinn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: afinn in /usr/local/lib/python3.6/dist-packages (0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq8OyIeKXF9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize afinn sentiment analyzer\n",
        "from afinn import Afinn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s07oIAF7kVC2",
        "colab_type": "text"
      },
      "source": [
        "On labellise nos commentaires deux fois :\n",
        "\n",
        "- Avec trois dimensions (postifif, négatif et neutre). L'implémentation de BERT du TP numéro 5 permet d'exploiter ces trois dimensions\n",
        "\n",
        "- Avec deux dimensions (positif et négatif) pour pouvoir exécuter une autre implémentation de BERT issue de github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm6oqlX4XIin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fonction permettant de labelliser nos ensembles\n",
        "\n",
        "# On met 3 labels\n",
        "\n",
        "def Labellisation_3_labels(texte):\n",
        "  af = Afinn()\n",
        "\n",
        "  # On a fixé les deux seuils en faisant des tests de cohérence sur les résultats obtenus\n",
        "  seuil_neg = -2\n",
        "  seuil_pos = 2\n",
        "  \n",
        "  # compute sentiment scores (polarity) and labels\n",
        "  sentiment_scores = [af.score(M) for M in texte]\n",
        "  sentiment_category = [2 if score > seuil_pos  # 2 == 'positive'\n",
        "                          else 0 if score < seuil_neg # 0 == 'negative\"\n",
        "                              else 1  # 1 == 'neutral'\n",
        "                                  for score in sentiment_scores]\n",
        "\n",
        "  return(sentiment_category)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGZLtz_MXMWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Labels_Train = Labellisation_3_labels(Train_label)\n",
        "Labels_Test_Trump_articles = Labellisation_3_labels(Test_Trump_articles_label)\n",
        "Labels_Test_Trump = Labellisation_3_labels(Test_Trump_label)\n",
        "Labels_Validation = Labellisation_3_labels(Validation_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InseiXPykrrb",
        "colab_type": "code",
        "outputId": "043e7103-40c4-4afa-f46c-bc8663980593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Test pour vérifier la labellisation\n",
        "print(Test_Trump_articles.commentBody[3])\n",
        "print('Sentiment :', Labels_Test_Trump_articles[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mike Pompeo Works the Hill\n",
            "Sentiment : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E1mX_IN2CwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fonction permettant de labelliser nos ensembles\n",
        "\n",
        "# On ne met que 2 labels\n",
        "\n",
        "def Labellisation_2_labels(texte):\n",
        "  af = Afinn()\n",
        "\n",
        "  # On a fixé les deux seuils en faisant des tests de cohérence sur les résultats obtenus\n",
        "  seuil = 0\n",
        "  \n",
        "  # compute sentiment scores (polarity) and labels\n",
        "  sentiment_scores = [af.score(M) for M in texte]\n",
        "  sentiment_category = [1 if score > seuil  # 'positive'\n",
        "                          else 0 # 'negative'\n",
        "                                  for score in sentiment_scores]\n",
        "\n",
        "  return(sentiment_category)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "armzgvrK2Tga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Labels_Train_2 = Labellisation_2_labels(Train_label)\n",
        "Labels_Test_Trump_articles_2 = Labellisation_2_labels(Test_Trump_articles_label)\n",
        "Labels_Test_Trump_2 = Labellisation_2_labels(Test_Trump_label)\n",
        "Labels_Validation_2 = Labellisation_2_labels(Validation_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKiBXnZu3yW7",
        "colab_type": "code",
        "outputId": "de906c68-fd50-40fb-8ede-5c7de6b00d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Test pour vérifier la labellisation\n",
        "print(Test_Trump_articles.commentBody[3])\n",
        "print('Sentiment :', Labels_Test_Trump_articles_2[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mike Pompeo Works the Hill\n",
            "Sentiment : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7bDbsCQZh63",
        "colab_type": "text"
      },
      "source": [
        "# DataFrames labellisés\n",
        "\n",
        "On va rassembler les ensembles destinés à BERT avec les labels correspondant dans de nouveaux DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv3ie-Dw1Ihx",
        "colab_type": "text"
      },
      "source": [
        "## Création des DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qdEh9T6alfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fonction permettant d'associer les textes avec les labels correspondants\n",
        "\n",
        "def DF_labels(texte, Labels) :\n",
        "  df_temp = [(texte[i], Labels[i]) for i in range(len(texte))]\n",
        "  df = pd.DataFrame(df_temp)\n",
        "  df.columns = ['text', 'label']\n",
        "  return(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8J40M6JZ0XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creation de la base des DataFrames avec la fonction\n",
        "\n",
        "df_TRAIN = DF_labels(Cleaned_Train, Labels_Train)\n",
        "df_TEST_Trump_articles = DF_labels(Cleaned_Test_Trump_articles, Labels_Test_Trump_articles)\n",
        "df_TEST_Trump = DF_labels(Cleaned_Test_Trump, Labels_Test_Trump)\n",
        "df_VALIDATION = DF_labels(Cleaned_Validation, Labels_Validation)\n",
        "\n",
        "df_TRAIN_2_labels = DF_labels(Cleaned_Train, Labels_Train_2)\n",
        "df_TEST_Trump_articles_2_labels = DF_labels(Cleaned_Test_Trump_articles, Labels_Test_Trump_articles_2)\n",
        "df_TEST_Trump_2_labels = DF_labels(Cleaned_Test_Trump, Labels_Test_Trump_2)\n",
        "df_VALIDATION_2_labels = DF_labels(Cleaned_Validation, Labels_Validation_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd7ZfWGzQ4Z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# On ajoute les colonnes contenant les articleID et les userID\n",
        "\n",
        "df_TRAIN['articleID'] = Train.articleID\n",
        "df_TRAIN['userID'] = Train.userID\n",
        "\n",
        "df_TEST_Trump_articles['articleID'] = Test_Trump_articles.articleID\n",
        "\n",
        "df_TEST_Trump['articleID'] = Test_Trump.articleID\n",
        "df_TEST_Trump['userID'] = Test_Trump.userID\n",
        "\n",
        "df_VALIDATION['articleID'] = Validation.articleID\n",
        "df_VALIDATION['userID'] = Validation.userID\n",
        "\n",
        "df_TRAIN_2_labels['articleID'] = Train.articleID\n",
        "df_TRAIN_2_labels['userID'] = Train.userID\n",
        "\n",
        "df_TEST_Trump_articles_2_labels['articleID'] = Test_Trump_articles.articleID\n",
        "\n",
        "df_TEST_Trump_2_labels['articleID'] = Test_Trump.articleID\n",
        "df_TEST_Trump_2_labels['userID'] = Test_Trump.userID\n",
        "\n",
        "df_VALIDATION_2_labels['articleID'] = Validation.articleID\n",
        "df_VALIDATION_2_labels['userID'] = Validation.userID"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGj8TC0wRzA-",
        "colab_type": "text"
      },
      "source": [
        "Nos ensembles sont maintenant nettoyés (et possèdent les stopwords), labellisés et prêts à être utilisés dans notre modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZzwRGXd4Biz",
        "colab_type": "code",
        "outputId": "2afea4dd-2df6-4eb5-f60e-69a35430e0a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "df_TEST_Trump_articles_2_labels.groupby('label').count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>articleID</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1743</td>\n",
              "      <td>1743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>368</td>\n",
              "      <td>368</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       text  articleID\n",
              "label                 \n",
              "0      1743       1743\n",
              "1       368        368"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcLe2go54Csu",
        "colab_type": "text"
      },
      "source": [
        "On constate que nos titres d'articles sur Trump sont majoritairement Négatifs (label = 0). Notre base de données est donc potentiellement déséquilibrée car influencée par ces titres.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT2-DhwTlapF",
        "colab_type": "text"
      },
      "source": [
        "## DataFrames finaux utilisables par BERT\n",
        "\n",
        "Nos DataFrames se sommes :\n",
        "*  Pour le training : df_TRAIN\n",
        "*  Pour la validation : df_VALIDATION\n",
        "*  Pour le test sur les titres des articles : df_TEST_Trump_articles\n",
        "*  Pour le test sur les commentaires sur Trump : df_TEST_Trump\n",
        "\n",
        "Les colonnes se nomment : 'text', 'label', 'articleID', 'userID'\n",
        "\n",
        "'userID' n'existe pas dans la base df_TEST_Trump_articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyHuYPlxaYJo",
        "colab_type": "code",
        "outputId": "c0f26520-de2b-44f1-cb43-b3abce5e0fe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_TRAIN.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>articleID</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joe biden , please !</td>\n",
              "      <td>1</td>\n",
              "      <td>5aad639447de81a901211e8b</td>\n",
              "      <td>12883090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i left teaching before i got in too deep . th...</td>\n",
              "      <td>0</td>\n",
              "      <td>5ab842b947de81a9012170d2</td>\n",
              "      <td>45540664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>integration psychologically is only possible ...</td>\n",
              "      <td>2</td>\n",
              "      <td>5abd855c47de81a901219c1c</td>\n",
              "      <td>75948691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>love this ... and her . what a relief that , ...</td>\n",
              "      <td>2</td>\n",
              "      <td>5aaf7c2147de81a901212679</td>\n",
              "      <td>59977368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>`` there is an international community that o...</td>\n",
              "      <td>0</td>\n",
              "      <td>5ab554d147de81a901216469</td>\n",
              "      <td>56137599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...    userID\n",
              "0                               joe biden , please !  ...  12883090\n",
              "1   i left teaching before i got in too deep . th...  ...  45540664\n",
              "2   integration psychologically is only possible ...  ...  75948691\n",
              "3   love this ... and her . what a relief that , ...  ...  59977368\n",
              "4   `` there is an international community that o...  ...  56137599\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UBEke2QQdjo",
        "colab_type": "code",
        "outputId": "db9239ca-a105-4d14-929e-8971fd59eb1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_TEST_Trump_articles.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>articleID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>meager support for blend of policy in replace...</td>\n",
              "      <td>1</td>\n",
              "      <td>58befc877c459f247962dbcb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>can this presidency be saved ?</td>\n",
              "      <td>1</td>\n",
              "      <td>589f6ff295d0e02474635d70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pence ’ s presidential pet</td>\n",
              "      <td>1</td>\n",
              "      <td>5892ec0795d0e0392607e28f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mike pompeo works the hill</td>\n",
              "      <td>1</td>\n",
              "      <td>5acffed0068401528a2a86e8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>trump sees trade loss by ignoring key sector</td>\n",
              "      <td>0</td>\n",
              "      <td>5aabeb5f47de81a90121150d</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                 articleID\n",
              "0   meager support for blend of policy in replace...  ...  58befc877c459f247962dbcb\n",
              "1                     can this presidency be saved ?  ...  589f6ff295d0e02474635d70\n",
              "2                         pence ’ s presidential pet  ...  5892ec0795d0e0392607e28f\n",
              "3                         mike pompeo works the hill  ...  5acffed0068401528a2a86e8\n",
              "4       trump sees trade loss by ignoring key sector  ...  5aabeb5f47de81a90121150d\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HA25bJGbdwE",
        "colab_type": "code",
        "outputId": "6c1ccfbf-250c-4f71-bfb2-94b60283f4e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_TEST_Trump.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>articleID</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bartolo  `` is there any evidence '' yes. hac...</td>\n",
              "      <td>1</td>\n",
              "      <td>5ab9862047de81a901217995</td>\n",
              "      <td>37674938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>reagan who did n't smoke advertised cigarette...</td>\n",
              "      <td>1</td>\n",
              "      <td>5ab136a147de81a901213555</td>\n",
              "      <td>62945206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>congress ' time to `` wake up soon '' happene...</td>\n",
              "      <td>1</td>\n",
              "      <td>5aaf7c1e47de81a901212671</td>\n",
              "      <td>59144840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>as long as republicans in congress allow trum...</td>\n",
              "      <td>0</td>\n",
              "      <td>5aac76e847de81a901211a5b</td>\n",
              "      <td>79969624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wow . i definitely wo n't be watching this sh...</td>\n",
              "      <td>2</td>\n",
              "      <td>5aba502547de81a901217e5f</td>\n",
              "      <td>79070806</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...    userID\n",
              "0   bartolo  `` is there any evidence '' yes. hac...  ...  37674938\n",
              "1   reagan who did n't smoke advertised cigarette...  ...  62945206\n",
              "2   congress ' time to `` wake up soon '' happene...  ...  59144840\n",
              "3   as long as republicans in congress allow trum...  ...  79969624\n",
              "4   wow . i definitely wo n't be watching this sh...  ...  79070806\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jtq5p0-ibfwo",
        "colab_type": "code",
        "outputId": "a37f4018-6187-45b4-be22-03d2a67062e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_VALIDATION.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>articleID</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>why would people who do n't have guns want to...</td>\n",
              "      <td>1</td>\n",
              "      <td>5aaf86b847de81a9012126a9</td>\n",
              "      <td>82004583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ben sasse . nebraska republican , is in trump...</td>\n",
              "      <td>0</td>\n",
              "      <td>5a9d563747de81a90120a1b7</td>\n",
              "      <td>21208144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>`` the bulletproof private transports preferr...</td>\n",
              "      <td>1</td>\n",
              "      <td>5aba19d147de81a901217cba</td>\n",
              "      <td>21694747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>reading the comments on here by times readers...</td>\n",
              "      <td>2</td>\n",
              "      <td>5a985b9a410cf7000162eb85</td>\n",
              "      <td>17788919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>let 's not complicate this . trump has also t...</td>\n",
              "      <td>1</td>\n",
              "      <td>5aa1143647de81a90120b853</td>\n",
              "      <td>14956507</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...    userID\n",
              "0   why would people who do n't have guns want to...  ...  82004583\n",
              "1   ben sasse . nebraska republican , is in trump...  ...  21208144\n",
              "2   `` the bulletproof private transports preferr...  ...  21694747\n",
              "3   reading the comments on here by times readers...  ...  17788919\n",
              "4   let 's not complicate this . trump has also t...  ...  14956507\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw56rdIk2rx9",
        "colab_type": "code",
        "outputId": "95a8f8ce-4071-42ad-b8df-edb579a061ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_TRAIN_2_labels.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>articleID</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>joe biden , please !</td>\n",
              "      <td>1</td>\n",
              "      <td>5aad639447de81a901211e8b</td>\n",
              "      <td>12883090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i left teaching before i got in too deep . th...</td>\n",
              "      <td>0</td>\n",
              "      <td>5ab842b947de81a9012170d2</td>\n",
              "      <td>45540664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>integration psychologically is only possible ...</td>\n",
              "      <td>1</td>\n",
              "      <td>5abd855c47de81a901219c1c</td>\n",
              "      <td>75948691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>love this ... and her . what a relief that , ...</td>\n",
              "      <td>1</td>\n",
              "      <td>5aaf7c2147de81a901212679</td>\n",
              "      <td>59977368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>`` there is an international community that o...</td>\n",
              "      <td>0</td>\n",
              "      <td>5ab554d147de81a901216469</td>\n",
              "      <td>56137599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...    userID\n",
              "0                               joe biden , please !  ...  12883090\n",
              "1   i left teaching before i got in too deep . th...  ...  45540664\n",
              "2   integration psychologically is only possible ...  ...  75948691\n",
              "3   love this ... and her . what a relief that , ...  ...  59977368\n",
              "4   `` there is an international community that o...  ...  56137599\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ1HUsFNGSag",
        "colab_type": "code",
        "outputId": "3040f95e-aa2b-4c02-c9e1-a1860e0df854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_TEST_Trump_2_labels.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>articleID</th>\n",
              "      <th>userID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bartolo  `` is there any evidence '' yes. hac...</td>\n",
              "      <td>1</td>\n",
              "      <td>5ab9862047de81a901217995</td>\n",
              "      <td>37674938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>reagan who did n't smoke advertised cigarette...</td>\n",
              "      <td>1</td>\n",
              "      <td>5ab136a147de81a901213555</td>\n",
              "      <td>62945206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>congress ' time to `` wake up soon '' happene...</td>\n",
              "      <td>0</td>\n",
              "      <td>5aaf7c1e47de81a901212671</td>\n",
              "      <td>59144840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>as long as republicans in congress allow trum...</td>\n",
              "      <td>0</td>\n",
              "      <td>5aac76e847de81a901211a5b</td>\n",
              "      <td>79969624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wow . i definitely wo n't be watching this sh...</td>\n",
              "      <td>1</td>\n",
              "      <td>5aba502547de81a901217e5f</td>\n",
              "      <td>79070806</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...    userID\n",
              "0   bartolo  `` is there any evidence '' yes. hac...  ...  37674938\n",
              "1   reagan who did n't smoke advertised cigarette...  ...  62945206\n",
              "2   congress ' time to `` wake up soon '' happene...  ...  59144840\n",
              "3   as long as republicans in congress allow trum...  ...  79969624\n",
              "4   wow . i definitely wo n't be watching this sh...  ...  79070806\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCOBTFhi7iyf",
        "colab_type": "text"
      },
      "source": [
        "## Création de fichiers CSV\n",
        "\n",
        "On fabrique des fichiers CSV à partir des nos 4 ensembles de données pour ensuite les utiliser facilement avec BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11eedvJ77v97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creation des CSV\n",
        "df_TRAIN.to_csv('df_TRAIN.csv', sep=';')\n",
        "df_TEST_Trump_articles.to_csv('df_TEST_Trump_articles.csv', sep=';')\n",
        "df_TEST_Trump.to_csv('df_TEST_Trump.csv', sep=';')\n",
        "df_VALIDATION.to_csv('df_VALIDATION.csv', sep=';')\n",
        "\n",
        "df_TRAIN_2_labels.to_csv('df_TRAIN_2.csv', sep=';')\n",
        "df_TEST_Trump_articles_2_labels.to_csv('df_TEST_Trump_articles_2.csv', sep=';')\n",
        "df_TEST_Trump_2_labels.to_csv('df_TEST_Trump_2.csv', sep=';')\n",
        "df_VALIDATION_2_labels.to_csv('df_VALIDATION_2.csv', sep=';')\n",
        "\n",
        "# dans les fichiers a gauche, on peut \"actualiser\" puis \"télécharger\" les bases "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YVV8RTp0nx_",
        "colab_type": "text"
      },
      "source": [
        "# BERT - A partir des Labs\n",
        "\n",
        "On utilise les codes du lab5 pour implémenter notre modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAvtLfkC0mXD",
        "colab_type": "code",
        "outputId": "918f5cae-1114-45bb-de7c-c647fe90f652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "# Installation de BERT\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 6.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 5.7MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 6.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 9.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 49.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.38)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 46.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.38)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=3121a9c48925a436a3f2747f0c9258144b742948167e04a4c69aac396990c11a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJcMnqrT-qeU",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing \n",
        "\n",
        "On introduit quelques fonctions de preprocessing pour améliorer les résultats de notre modèle.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1j7364T7G8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fonctions de Preprocessing\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer, AutoModel, AutoTokenizer\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class SSTDataset(Dataset):\n",
        "\n",
        "    def __init__(self, filename, maxlen, model_name='bert-base-uncased'):\n",
        "\n",
        "        #Store the contents of the file in a pandas dataframe\n",
        "        self.df = pd.read_csv(filename, delimiter = ';')\n",
        "\n",
        "        #Initialize the BERT tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        #Selecting the text and label at the specified index in the data frame\n",
        "        sentence = self.df.loc[index, 'text']\n",
        "        label = self.df.loc[index, 'label']\n",
        "\n",
        "        #Preprocessing the text to be suitable for BERT\n",
        "        tokens = self.tokenizer.tokenize(sentence) #Tokenize the sentence\n",
        "        if self.tokenizer.cls_token is None:\n",
        "          bos_token = self.tokenizer.bos_token\n",
        "        else:\n",
        "          bos_token = self.tokenizer.cls_token\n",
        "          \n",
        "        if self.tokenizer.sep_token is None:\n",
        "          eos_token = self.tokenizer.eos_token\n",
        "        else:\n",
        "          eos_token = self.tokenizer.sep_token\n",
        "        \n",
        "        tokens = [bos_token] + tokens + [eos_token] #Insering the CLS and SEP token in the beginning and end of the sentence\n",
        "        if len(tokens) < self.maxlen:\n",
        "            tokens = tokens + [self.tokenizer.pad_token for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
        "        else:\n",
        "            tokens = tokens[:self.maxlen-1] + [eos_token] #Prunning the list to be of specified max length\n",
        "\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
        "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpweNOss7Vss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating instances of training and validation set\n",
        "train_set = SSTDataset(filename = '/content/df_TRAIN.csv', maxlen = 30, model_name='bert-base-uncased')\n",
        "val_set = SSTDataset(filename = '/content/df_VALIDATION.csv', maxlen = 30, model_name='bert-base-uncased')\n",
        "\n",
        "test_set = SSTDataset(filename = '/content/df_TEST_Trump.csv', maxlen = 30, model_name='bert-base-uncased')\n",
        "\n",
        "# Creating intsances of training and validation dataloaders\n",
        "train_loader = DataLoader(train_set, batch_size = 4, num_workers = 5)\n",
        "val_loader = DataLoader(val_set, batch_size = 4, num_workers = 5)\n",
        "test_loader = DataLoader(test_set, batch_size = 4, num_workers = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWmC4x618W_1",
        "colab_type": "code",
        "outputId": "f038a4fa-2d50-4f81-c816-ced99e723328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# get the number of sentences\n",
        "print(train_set.__len__(), \"number of sentence in training set\")\n",
        "print(val_set.__len__(), \"number of sentence in validation set\")\n",
        "\n",
        "# get  tokenized sentence indexed by 1 \n",
        "train_set.__getitem__(1) # "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40000 number of sentence in training set\n",
            "10000 number of sentence in validation set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  101,  1045,  2187,  4252,  2077,  1045,  2288,  1999,  2205,  2784,\n",
              "          1012,  1996, 27928,  1005,  2197, 18402,  2020,  1996,  2493,  1010,\n",
              "          1998,  1996,  2493,  1005,  2197, 18402,  2020, 17842,  2005,   102]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1]),\n",
              " 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Rrhmn32FkkM",
        "colab_type": "text"
      },
      "source": [
        "##  GPU\n",
        "\n",
        "Veuillez vérifier que le mode d'Exécution est mis sur \"GPU\" afin d'accélere les calculs.\n",
        "\n",
        "Pour se faire :\n",
        "*  cliquez sur \"Exécution\"\n",
        "*  cliquez sur \"Modifier le type d'exécution\"\n",
        "* Sélectionnez \"GPU\" dans \"Accélérateur matériel\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp91C8XpAw98",
        "colab_type": "code",
        "outputId": "af87c423-f2c8-48e4-def0-8414ec6b77fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# to checkout the GPU activity (cf. Volatile GPU-Util %)\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 11 12:37:09 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl2Xip2h-eul",
        "colab_type": "text"
      },
      "source": [
        "## Model d'analyse des sentiments avec pytorch \n",
        "\n",
        "On utilise un modèle de langage masqué pré-entraîné comme un module de notre modèle d'analyse des sentiments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IxMfs-F-ZLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained_model_name='bert-base-uncased'):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        \n",
        "        #Loading Mask Language Model \n",
        "        self.encoder = AutoModel.from_pretrained(pretrained_model_name)\n",
        "        #we append an extra layer for Classification (it will be randomly initialized)\n",
        "        self.cls_layer = nn.Linear(self.encoder.pooler.dense.out_features, 1)\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        '''\n",
        "        Inputs:\n",
        "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
        "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
        "        '''\n",
        "\n",
        "        #Feeding the input to BERT model to obtain contextualized representations\n",
        "        cont_reps, _ = self.encoder(seq, attention_mask = attn_masks)\n",
        "\n",
        "        #Obtaining the representation of [CLS] head\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "\n",
        "        #Feeding cls_rep to the classifier layer\n",
        "        logits = self.cls_layer(cls_rep)\n",
        "\n",
        "        return logits\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcr5Q-30-Z1C",
        "colab_type": "code",
        "outputId": "daef737e-463d-4252-e7c1-ee8c72ecc5eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "774d188d80b94e5dacb131161a3bec20",
            "f169c4fdae97400983c160d7223bda99",
            "f0ba10e3b2d1476092d7ae85f63813ff",
            "720067f12c32467f8158ebcabfbe5c53",
            "fbc9c74f27bd4f03afa40f2f7fbcda55",
            "842a5658a4164ea8a83047f121cf02c0",
            "6318e50072324ea99973c3828a3ba81d",
            "0bebf503c56942c995a9bd59af3953aa"
          ]
        }
      },
      "source": [
        "sentiment_model = SentimentClassifier('bert-base-uncased')\n",
        "# if gpu mode\n",
        "sentiment_model = sentiment_model.to(\"cuda\")\n",
        "# to check if the weights of the model are in gpu : \n",
        "# sentiment_model.cls_layer.weight.is_cuda\n",
        "# can checkout all the layers by running \n",
        "#sentiment_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "774d188d80b94e5dacb131161a3bec20",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxTqNwx1GXOP",
        "colab_type": "text"
      },
      "source": [
        "## Training Process\n",
        "\n",
        "On doit définir :\n",
        "- une perte \n",
        "\n",
        "- un optimizer \n",
        "\n",
        "\n",
        "Ici, on va utiliser une variante de la descente de gradient stochastique appelée ADAM.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TNqGfcnGWrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Paramètres\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "opti = optim.Adam(sentiment_model.parameters(), lr = 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_pXeNvjGnkU",
        "colab_type": "text"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98iVsITQGpo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fonction d'apprentissage\n",
        "\n",
        "import pdb\n",
        "def train(model, criterion, opti, train_loader, val_loader, max_eps=1, gpu=False, print_every=1,validate_every=1):\n",
        "    print('Training ...')\n",
        "    print('\\n')\n",
        "    if gpu:\n",
        "      model = model.to(\"cuda\")\n",
        "    for ep in range(max_eps):\n",
        "        \n",
        "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "            #Clear gradients\n",
        "            opti.zero_grad()  \n",
        "            #Converting these to cuda tensors\n",
        "            if gpu:\n",
        "              seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "            #Obtaining the logits from the model\n",
        "            logits = model(seq, attn_masks)\n",
        "\n",
        "            #Computing loss\n",
        "            loss = criterion(logits.squeeze(-1), labels.float())\n",
        "\n",
        "            #Backpropagating the gradients\n",
        "            loss.backward()\n",
        "\n",
        "            #Optimization step\n",
        "            opti.step()\n",
        "            if (it + 1) % print_every == 0:\n",
        "                accuracy = torch.sum((logits>0).int().squeeze(1)==labels)/float(labels.size(0))\n",
        "                print(\"Iteration {} of epoch {} complete. Loss : {} / Accuracy : {} \".format(it+1, ep+1, loss.item(),accuracy))\n",
        "            if it>1000:\n",
        "              break\n",
        "        if ep % validate_every==0:\n",
        "          n_batch_validation = 0\n",
        "          loss_validation = 0\n",
        "          accuracy_validation = 0\n",
        "          for it, (seq, attn_masks, labels) in enumerate(val_loader):\n",
        "            #Clear gradients\n",
        "            \n",
        "            if gpu:\n",
        "              seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "            #Obtaining the logits from the model\n",
        "            logits_val = model(seq, attn_masks)\n",
        "            n_batch_validation+=1\n",
        "            #Computing loss\n",
        "           \n",
        "            _loss = float(criterion(logits_val.squeeze(-1), labels.float()))\n",
        "            _accu = float(torch.sum((logits_val>0).int().squeeze(1)==labels)/float(labels.size(0)))\n",
        "           \n",
        "            loss_validation += _loss\n",
        "            accuracy_validation += _accu\n",
        "          print(\"EVALUATION Validation set : Mean Loss : {} / Mean Accuracy : {}\".format(loss_validation/n_batch_validation, accuracy_validation/n_batch_validation))\n",
        "          print('\\n')\n",
        "\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoDTs18_G0vF",
        "colab_type": "code",
        "outputId": "100a0704-5350-4ece-f8ff-ebd3446cb2fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training\n",
        "train(sentiment_model, criterion, opti, train_loader, val_loader, max_eps=10, print_every=100, gpu=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training ...\n",
            "\n",
            "\n",
            "Iteration 100 of epoch 1 complete. Loss : 0.0 / Accuracy : 1.0 \n",
            "Iteration 200 of epoch 1 complete. Loss : -159.0705108642578 / Accuracy : 0.5 \n",
            "Iteration 300 of epoch 1 complete. Loss : 0.0 / Accuracy : 0.0 \n",
            "Iteration 400 of epoch 1 complete. Loss : -80.37785339355469 / Accuracy : 0.25 \n",
            "Iteration 500 of epoch 1 complete. Loss : -80.34168243408203 / Accuracy : 0.25 \n",
            "Iteration 600 of epoch 1 complete. Loss : 0.0 / Accuracy : 0.5 \n",
            "Iteration 700 of epoch 1 complete. Loss : -80.62312316894531 / Accuracy : 0.75 \n",
            "Iteration 800 of epoch 1 complete. Loss : -80.98309326171875 / Accuracy : 0.25 \n",
            "Iteration 900 of epoch 1 complete. Loss : -246.12525939941406 / Accuracy : 0.25 \n",
            "Iteration 1000 of epoch 1 complete. Loss : -82.7635726928711 / Accuracy : 0.75 \n",
            "EVALUATION Validation set : Mean Loss : -12.088721524047852 / Mean Accuracy : 0.4321\n",
            "\n",
            "\n",
            "Iteration 100 of epoch 2 complete. Loss : 0.0 / Accuracy : 1.0 \n",
            "Iteration 200 of epoch 2 complete. Loss : -167.5873260498047 / Accuracy : 0.5 \n",
            "Iteration 300 of epoch 2 complete. Loss : 0.0 / Accuracy : 0.0 \n",
            "Iteration 400 of epoch 2 complete. Loss : -84.6559829711914 / Accuracy : 0.25 \n",
            "Iteration 500 of epoch 2 complete. Loss : -84.6656265258789 / Accuracy : 0.25 \n",
            "Iteration 600 of epoch 2 complete. Loss : 0.0 / Accuracy : 0.5 \n",
            "Iteration 700 of epoch 2 complete. Loss : -84.89616394042969 / Accuracy : 0.75 \n",
            "Iteration 800 of epoch 2 complete. Loss : -85.27423095703125 / Accuracy : 0.25 \n",
            "Iteration 900 of epoch 2 complete. Loss : -259.0700988769531 / Accuracy : 0.25 \n",
            "Iteration 1000 of epoch 2 complete. Loss : -87.0954818725586 / Accuracy : 0.75 \n",
            "EVALUATION Validation set : Mean Loss : -12.721297085571289 / Mean Accuracy : 0.4321\n",
            "\n",
            "\n",
            "Iteration 100 of epoch 3 complete. Loss : 0.0 / Accuracy : 1.0 \n",
            "Iteration 200 of epoch 3 complete. Loss : -176.29742431640625 / Accuracy : 0.5 \n",
            "Iteration 300 of epoch 3 complete. Loss : 1.52587890625e-05 / Accuracy : 0.0 \n",
            "Iteration 400 of epoch 3 complete. Loss : -89.03044128417969 / Accuracy : 0.25 \n",
            "Iteration 500 of epoch 3 complete. Loss : -89.0399169921875 / Accuracy : 0.25 \n",
            "Iteration 600 of epoch 3 complete. Loss : -7.62939453125e-06 / Accuracy : 0.5 \n",
            "Iteration 700 of epoch 3 complete. Loss : -89.2882080078125 / Accuracy : 0.75 \n",
            "Iteration 800 of epoch 3 complete. Loss : -89.66326904296875 / Accuracy : 0.25 \n",
            "Iteration 900 of epoch 3 complete. Loss : -272.3089294433594 / Accuracy : 0.25 \n",
            "Iteration 1000 of epoch 3 complete. Loss : -91.5248794555664 / Accuracy : 0.75 \n",
            "EVALUATION Validation set : Mean Loss : -13.368106002807616 / Mean Accuracy : 0.4321\n",
            "\n",
            "\n",
            "Iteration 100 of epoch 4 complete. Loss : 0.0 / Accuracy : 1.0 \n",
            "Iteration 200 of epoch 4 complete. Loss : -185.20245361328125 / Accuracy : 0.5 \n",
            "Iteration 300 of epoch 4 complete. Loss : 0.0 / Accuracy : 0.0 \n",
            "Iteration 400 of epoch 4 complete. Loss : -93.50232696533203 / Accuracy : 0.25 \n",
            "Iteration 500 of epoch 4 complete. Loss : -93.51092529296875 / Accuracy : 0.25 \n",
            "Iteration 600 of epoch 4 complete. Loss : 0.0 / Accuracy : 0.5 \n",
            "Iteration 700 of epoch 4 complete. Loss : -93.75859069824219 / Accuracy : 0.75 \n",
            "Iteration 800 of epoch 4 complete. Loss : -94.14877319335938 / Accuracy : 0.25 \n",
            "Iteration 900 of epoch 4 complete. Loss : -285.83563232421875 / Accuracy : 0.25 \n",
            "Iteration 1000 of epoch 4 complete. Loss : -96.05084228515625 / Accuracy : 0.75 \n",
            "EVALUATION Validation set : Mean Loss : -14.029008276367188 / Mean Accuracy : 0.4321\n",
            "\n",
            "\n",
            "Iteration 100 of epoch 5 complete. Loss : 0.0 / Accuracy : 1.0 \n",
            "Iteration 200 of epoch 5 complete. Loss : -194.30062866210938 / Accuracy : 0.5 \n",
            "Iteration 300 of epoch 5 complete. Loss : 0.0 / Accuracy : 0.0 \n",
            "Iteration 400 of epoch 5 complete. Loss : -98.07074737548828 / Accuracy : 0.25 \n",
            "Iteration 500 of epoch 5 complete. Loss : -98.07757568359375 / Accuracy : 0.25 \n",
            "Iteration 600 of epoch 5 complete. Loss : 0.0 / Accuracy : 0.5 \n",
            "Iteration 700 of epoch 5 complete. Loss : -98.33358001708984 / Accuracy : 0.75 \n",
            "Iteration 800 of epoch 5 complete. Loss : -98.73103332519531 / Accuracy : 0.25 \n",
            "Iteration 900 of epoch 5 complete. Loss : -299.6543273925781 / Accuracy : 0.25 \n",
            "Iteration 1000 of epoch 5 complete. Loss : -100.67366790771484 / Accuracy : 0.75 \n",
            "EVALUATION Validation set : Mean Loss : -14.704055276489258 / Mean Accuracy : 0.4321\n",
            "\n",
            "\n",
            "Iteration 100 of epoch 6 complete. Loss : 0.0 / Accuracy : 1.0 \n",
            "Iteration 200 of epoch 6 complete. Loss : -203.59254455566406 / Accuracy : 0.5 \n",
            "Iteration 300 of epoch 6 complete. Loss : 0.0 / Accuracy : 0.0 \n",
            "Iteration 400 of epoch 6 complete. Loss : -102.73607635498047 / Accuracy : 0.25 \n",
            "Iteration 500 of epoch 6 complete. Loss : -102.74471282958984 / Accuracy : 0.25 \n",
            "Iteration 600 of epoch 6 complete. Loss : -1.52587890625e-05 / Accuracy : 0.5 \n",
            "Iteration 700 of epoch 6 complete. Loss : -103.00540161132812 / Accuracy : 0.75 \n",
            "Iteration 800 of epoch 6 complete. Loss : -103.41034698486328 / Accuracy : 0.25 \n",
            "Iteration 900 of epoch 6 complete. Loss : -313.7612609863281 / Accuracy : 0.25 \n",
            "Iteration 1000 of epoch 6 complete. Loss : -105.3933334350586 / Accuracy : 0.75 \n",
            "EVALUATION Validation set : Mean Loss : -15.393242303466797 / Mean Accuracy : 0.4321\n",
            "\n",
            "\n",
            "Iteration 100 of epoch 7 complete. Loss : 0.0 / Accuracy : 1.0 \n",
            "Iteration 200 of epoch 7 complete. Loss : -213.02801513671875 / Accuracy : 0.5 \n",
            "Iteration 300 of epoch 7 complete. Loss : -1.52587890625e-05 / Accuracy : 0.0 \n",
            "Iteration 400 of epoch 7 complete. Loss : -107.49507904052734 / Accuracy : 0.25 \n",
            "Iteration 500 of epoch 7 complete. Loss : -107.4804458618164 / Accuracy : 0.25 \n",
            "Iteration 600 of epoch 7 complete. Loss : 0.0 / Accuracy : 0.5 \n",
            "Iteration 700 of epoch 7 complete. Loss : -107.78057861328125 / Accuracy : 0.75 \n",
            "Iteration 800 of epoch 7 complete. Loss : -108.18592071533203 / Accuracy : 0.25 \n",
            "Iteration 900 of epoch 7 complete. Loss : -328.1681213378906 / Accuracy : 0.25 \n",
            "Iteration 1000 of epoch 7 complete. Loss : -110.20911407470703 / Accuracy : 0.75 \n",
            "EVALUATION Validation set : Mean Loss : -16.096480715942384 / Mean Accuracy : 0.4321\n",
            "\n",
            "\n",
            "Iteration 100 of epoch 8 complete. Loss : 0.0 / Accuracy : 1.0 \n",
            "Iteration 200 of epoch 8 complete. Loss : -222.7561492919922 / Accuracy : 0.5 \n",
            "Iteration 300 of epoch 8 complete. Loss : 0.0 / Accuracy : 0.0 \n",
            "Iteration 400 of epoch 8 complete. Loss : -112.35639190673828 / Accuracy : 0.25 \n",
            "Iteration 500 of epoch 8 complete. Loss : -112.36730194091797 / Accuracy : 0.25 \n",
            "Iteration 600 of epoch 8 complete. Loss : 0.0 / Accuracy : 0.5 \n",
            "Iteration 700 of epoch 8 complete. Loss : -112.63008117675781 / Accuracy : 0.75 \n",
            "Iteration 800 of epoch 8 complete. Loss : -113.05811309814453 / Accuracy : 0.25 \n",
            "Iteration 900 of epoch 8 complete. Loss : -342.8570556640625 / Accuracy : 0.25 \n",
            "Iteration 1000 of epoch 8 complete. Loss : -115.1217269897461 / Accuracy : 0.75 \n",
            "EVALUATION Validation set : Mean Loss : -16.813839819335936 / Mean Accuracy : 0.4321\n",
            "\n",
            "\n",
            "Iteration 100 of epoch 9 complete. Loss : 0.0 / Accuracy : 1.0 \n",
            "Iteration 200 of epoch 9 complete. Loss : -232.62759399414062 / Accuracy : 0.5 \n",
            "Iteration 300 of epoch 9 complete. Loss : 0.0 / Accuracy : 0.0 \n",
            "Iteration 400 of epoch 9 complete. Loss : -117.31139373779297 / Accuracy : 0.25 \n",
            "Iteration 500 of epoch 9 complete. Loss : -117.3221664428711 / Accuracy : 0.25 \n",
            "Iteration 600 of epoch 9 complete. Loss : 7.62939453125e-06 / Accuracy : 0.5 \n",
            "Iteration 700 of epoch 9 complete. Loss : -117.60006713867188 / Accuracy : 0.75 \n",
            "Iteration 800 of epoch 9 complete. Loss : -118.02770233154297 / Accuracy : 0.25 \n",
            "Iteration 900 of epoch 9 complete. Loss : -357.83831787109375 / Accuracy : 0.25 \n",
            "Iteration 1000 of epoch 9 complete. Loss : -120.1316146850586 / Accuracy : 0.75 \n",
            "EVALUATION Validation set : Mean Loss : -17.545402389526366 / Mean Accuracy : 0.4321\n",
            "\n",
            "\n",
            "Iteration 100 of epoch 10 complete. Loss : 0.0 / Accuracy : 1.0 \n",
            "Iteration 200 of epoch 10 complete. Loss : -242.69354248046875 / Accuracy : 0.5 \n",
            "Iteration 300 of epoch 10 complete. Loss : 0.0 / Accuracy : 0.0 \n",
            "Iteration 400 of epoch 10 complete. Loss : -122.36368560791016 / Accuracy : 0.25 \n",
            "Iteration 500 of epoch 10 complete. Loss : -122.3751449584961 / Accuracy : 0.25 \n",
            "Iteration 600 of epoch 10 complete. Loss : 0.0 / Accuracy : 0.5 \n",
            "Iteration 700 of epoch 10 complete. Loss : -122.67300415039062 / Accuracy : 0.75 \n",
            "Iteration 800 of epoch 10 complete. Loss : -123.09410858154297 / Accuracy : 0.25 \n",
            "Iteration 900 of epoch 10 complete. Loss : -373.1082763671875 / Accuracy : 0.25 \n",
            "Iteration 1000 of epoch 10 complete. Loss : -125.23834228515625 / Accuracy : 0.75 \n",
            "EVALUATION Validation set : Mean Loss : -18.29110065612793 / Mean Accuracy : 0.4321\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26-H-QUag3_c",
        "colab_type": "text"
      },
      "source": [
        "On observe que la perte moyenne diminue au fur et à mesure que les époques passent. Cependant, la précision moyenne n'évolue pas (\"Accuracy : 0.4321\"), ce qui est étonannt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX9TQqRHYblA",
        "colab_type": "text"
      },
      "source": [
        "## Prédiction (Tests)\n",
        "\n",
        "On applique notre modèle entraîné aux ensembles de Test pour voir la pertinence de notre modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH6WfBOHR4Dp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fonction de Tests\n",
        "\n",
        "import pdb\n",
        "def test(model, test_loader, gpu=False):\n",
        "    # Test\n",
        "    n_batch_validation = 0\n",
        "    loss_validation = 0\n",
        "    accuracy_validation = 0\n",
        "    for it, (seq, attn_masks, labels) in enumerate(test_loader):\n",
        "      if gpu:\n",
        "        seq, attn_masks, labels = seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
        "      #Obtaining the logits from the model\n",
        "      logits_val = model(seq, attn_masks)\n",
        "      n_batch_validation+=1\n",
        "           \n",
        "      _loss = float(criterion(logits_val.squeeze(-1), labels.float()))\n",
        "      _accu = float(torch.sum((logits_val>0).int().squeeze(1)==labels)/float(labels.size(0)))\n",
        "      \n",
        "      loss_validation += _loss\n",
        "      accuracy_validation += _accu\n",
        "\n",
        "    print('Testing ...')\n",
        "    print(\"EVALUATION Test set : Mean Loss : {} / Mean Accuracy : {}\".format(loss_validation/n_batch_validation, accuracy_validation/n_batch_validation))\n",
        "\n",
        "\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hDg-58_TekY",
        "colab_type": "code",
        "outputId": "851461ff-e9f7-4f49-b1ee-1a211fa85bae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Testing\n",
        "test(sentiment_model, train_loader, gpu=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing ...\n",
            "EVALUATION Test set : Mean Loss : -21.29785696029663 / Mean Accuracy : 0.4278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvse07V-lPJi",
        "colab_type": "text"
      },
      "source": [
        "On constate que la précision est assez faible (près de 43%), on va donc exploiter une autre implémentation de BERT issue de github."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XffrSF7FnR-O",
        "colab_type": "text"
      },
      "source": [
        "#  BERT - A partir d'un Github\n",
        "\n",
        "On utilise les codes d'un Github BERT sur la base IMBD pour implémenter notre modèle sur notre base de commentaires du NYT. Pour pouvoir exploiter cette méthode, on utilise une classification binaire.\n",
        "Lien du Github BERT : https://github.com/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK30C-TECMlZ",
        "colab_type": "text"
      },
      "source": [
        "##  Tenserflow 1.14\n",
        "\n",
        "Il faut importer Tensorflow 1.14 pour pouvoir utiliser ce code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqydSZqvoSPP",
        "colab_type": "code",
        "outputId": "059a2433-4cd7-4a93-db5b-d323ee359586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpH7hsxeopGj",
        "colab_type": "code",
        "outputId": "e29421f2-17aa-44ed-9de5-fc1e8b137150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        }
      },
      "source": [
        "!pip uninstall tensorflow -y\n",
        "!pip install tensorflow==1.14"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.15.2:\n",
            "  Successfully uninstalled tensorflow-1.15.2\n",
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 96kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.28.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.2)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 2.2.0rc2\n",
            "    Uninstalling tensorflow-2.2.0rc2:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Successfully installed tensorboard-2.2.0 tensorflow-1.14.0 tensorflow-estimator-2.2.0rc0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF0Px4HJCXr9",
        "colab_type": "text"
      },
      "source": [
        "Il faut relancer l'environnement pour utiliser Tensorflow 1.14"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArH103PBouOF",
        "colab_type": "code",
        "outputId": "723af416-7bae-48bc-ef9e-c8caff0d71d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vérification de la version de Tensorflow\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"Now running TensorFlow version %s on Colab!\" %tf.VERSION)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now running TensorFlow version 1.14.0 on Colab!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmfGCetcCjMR",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaZTPYF8owwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I___dV6xoxvn",
        "colab_type": "code",
        "outputId": "28a59e03-b0e7-4e26-ab23-a51978871d2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 26.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 13.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL8RwbJRo1e4",
        "colab_type": "code",
        "outputId": "8e63d082-3c89-4b9f-98d4-1b5b7f199702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhv_J0bOltVh",
        "colab_type": "text"
      },
      "source": [
        "On met les bases de données au bon format pour le modèle BERT pré-entraîné  :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQLBX6Amt8IX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('/content/df_TRAIN_2.csv', delimiter=';')\n",
        "test = pd.read_csv('/content/df_TEST_Trump_2.csv', delimiter=';')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVSxBLeBpWOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'text'\n",
        "LABEL_COLUMN = 'label'\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "label_list = [0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4RNXhIhpiCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lue4oeEKlyd2",
        "colab_type": "text"
      },
      "source": [
        "On charge le modèle BERT qu'on va utiliser (bert base uncased) et on initialise la tokenization qui va principalement :\n",
        "- séparer les commentaires en tokens \n",
        "- faire correspondre chaque token à un id \n",
        "- ajouter les tokens spéciaux de début (cls) et de fin (sep) de séquence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34K5FaR9pmmf",
        "colab_type": "code",
        "outputId": "4f013b1c-8946-4287-c61b-13159915c348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-etbJ9bzpo7J",
        "colab_type": "code",
        "outputId": "4abb02d9-b2a5-4d12-f371-2c4cf299fe7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Test d'un exemple\n",
        "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'here',\n",
              " \"'\",\n",
              " 's',\n",
              " 'an',\n",
              " 'example',\n",
              " 'of',\n",
              " 'using',\n",
              " 'the',\n",
              " 'bert',\n",
              " 'token',\n",
              " '##izer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL6mHv9Jl-mc",
        "colab_type": "text"
      },
      "source": [
        "On s'interesse à la longeur de nos commentaires avant de fixer la longueur des séquences qui seront analysées"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JSYMJh_l_M0",
        "colab_type": "code",
        "outputId": "7ae28b0f-d3c8-4c40-ec0d-5e9995107620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "#si ce n'est pas déjà exécuté :\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 25.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 31.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 36.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 32.1MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 21.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 18.2MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 17.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 16.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 16.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 47.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.38)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 27.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.38)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=2203ecd1c587b7f8e98e7da7c2c5d5744c2bfd164a0f46dce712a5e776903549\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOjeDZrGmB8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_length_test = pd.DataFrame(data=df_TRAIN)\n",
        "comments_train = df_length_test.text.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHUgIH3CmGP8",
        "colab_type": "code",
        "outputId": "09d55050-8bae-441e-ecd6-d79303f8056f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "a3516e0c0fab4e189848970206e57af2",
            "3e0744cfa16c4e57a977e79dd8486a15",
            "6c5b5529160647e7a3ce64c2055c6e07",
            "9afd6f006e4544589ad8fb786e3a014c",
            "72e5844ad30140a1aaa5691c212662ba",
            "7a9daed2179b4e388ab96460c459b347",
            "fab3d5480ab74d7cbc756737e4edd319",
            "9f2a571c46194b29bae7cfbe632b5684"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenz = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3516e0c0fab4e189848970206e57af2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5xIgIYHmIc1",
        "colab_type": "code",
        "outputId": "ea552041-6060-4798-af98-39ce843072da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "length = []\n",
        "for i in range(comments_train.shape[0]):\n",
        " length.append(len(tokenz.tokenize(comments_train[i])))\n",
        "\n",
        "plt.hist(length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.7236e+04, 1.1398e+04, 5.4280e+03, 2.6880e+03, 1.6460e+03,\n",
              "        1.4250e+03, 1.4200e+02, 2.6000e+01, 9.0000e+00, 2.0000e+00]),\n",
              " array([  1.,  60., 119., 178., 237., 296., 355., 414., 473., 532., 591.]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAyFonVqmNQH",
        "colab_type": "text"
      },
      "source": [
        "On choisit de fixer la longueur de nos commentaires à 128 tokens, principalement par soucis de ressources computationelles et parce que près des deux tiers de nos commentaires respectent cette longueur maximale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOpmmZG2puO6",
        "colab_type": "code",
        "outputId": "016cb110-e1c4-44ab-94e0-ae42fc511e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 40000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 40000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] joe bid ##en , please ! [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] joe bid ##en , please ! [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3533 7226 2368 1010 3531 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3533 7226 2368 1010 3531 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i left teaching before i got in too deep . the principals ' last priorities were the students , and the students ' last priorities were accountability for their ( lack of ) actions . noon ##e seemed to be in charge of academics except bureau ##crats who worked far from any school . as a result , workplace ##s held a constant threat of violence , lack of standards , and helpless ##ness . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i left teaching before i got in too deep . the principals ' last priorities were the students , and the students ' last priorities were accountability for their ( lack of ) actions . noon ##e seemed to be in charge of academics except bureau ##crats who worked far from any school . as a result , workplace ##s held a constant threat of violence , lack of standards , and helpless ##ness . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2187 4252 2077 1045 2288 1999 2205 2784 1012 1996 27928 1005 2197 18402 2020 1996 2493 1010 1998 1996 2493 1005 2197 18402 2020 17842 2005 2037 1006 3768 1997 1007 4506 1012 11501 2063 2790 2000 2022 1999 3715 1997 15032 3272 4879 23423 2040 2499 2521 2013 2151 2082 1012 2004 1037 2765 1010 16165 2015 2218 1037 5377 5081 1997 4808 1010 3768 1997 4781 1010 1998 13346 2791 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2187 4252 2077 1045 2288 1999 2205 2784 1012 1996 27928 1005 2197 18402 2020 1996 2493 1010 1998 1996 2493 1005 2197 18402 2020 17842 2005 2037 1006 3768 1997 1007 4506 1012 11501 2063 2790 2000 2022 1999 3715 1997 15032 3272 4879 23423 2040 2499 2521 2013 2151 2082 1012 2004 1037 2765 1010 16165 2015 2218 1037 5377 5081 1997 4808 1010 3768 1997 4781 1010 1998 13346 2791 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] integration psychological ##ly is only possible when understand who we are , where we come from and where we are going ( to para ##ph ##rase ella baker ) . evolution provides part of the story . ivo ##lu ##tion ( the evolution of human self ##con ##sc ##ious ##ness ) completes the picture . there will always be fundamental differences between humans as we evolve or mature in self ##con ##sc ##ious ##ness . e ##war ##rio ##rs will forever be conflict ##ed . the more experienced i ##war ##rio ##rs have better is ##ight ‚ they can see more of the big picture and the whole ##ness and sacred ##ness of all things . they are the peace makers . they do not hate [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] integration psychological ##ly is only possible when understand who we are , where we come from and where we are going ( to para ##ph ##rase ella baker ) . evolution provides part of the story . ivo ##lu ##tion ( the evolution of human self ##con ##sc ##ious ##ness ) completes the picture . there will always be fundamental differences between humans as we evolve or mature in self ##con ##sc ##ious ##ness . e ##war ##rio ##rs will forever be conflict ##ed . the more experienced i ##war ##rio ##rs have better is ##ight ‚ they can see more of the big picture and the whole ##ness and sacred ##ness of all things . they are the peace makers . they do not hate [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 8346 8317 2135 2003 2069 2825 2043 3305 2040 2057 2024 1010 2073 2057 2272 2013 1998 2073 2057 2024 2183 1006 2000 11498 8458 23797 11713 6243 1007 1012 6622 3640 2112 1997 1996 2466 1012 28346 7630 3508 1006 1996 6622 1997 2529 2969 8663 11020 6313 2791 1007 28123 1996 3861 1012 2045 2097 2467 2022 8050 5966 2090 4286 2004 2057 19852 2030 9677 1999 2969 8663 11020 6313 2791 1012 1041 9028 9488 2869 2097 5091 2022 4736 2098 1012 1996 2062 5281 1045 9028 9488 2869 2031 2488 2003 18743 1522 2027 2064 2156 2062 1997 1996 2502 3861 1998 1996 2878 2791 1998 6730 2791 1997 2035 2477 1012 2027 2024 1996 3521 11153 1012 2027 2079 2025 5223 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 8346 8317 2135 2003 2069 2825 2043 3305 2040 2057 2024 1010 2073 2057 2272 2013 1998 2073 2057 2024 2183 1006 2000 11498 8458 23797 11713 6243 1007 1012 6622 3640 2112 1997 1996 2466 1012 28346 7630 3508 1006 1996 6622 1997 2529 2969 8663 11020 6313 2791 1007 28123 1996 3861 1012 2045 2097 2467 2022 8050 5966 2090 4286 2004 2057 19852 2030 9677 1999 2969 8663 11020 6313 2791 1012 1041 9028 9488 2869 2097 5091 2022 4736 2098 1012 1996 2062 5281 1045 9028 9488 2869 2031 2488 2003 18743 1522 2027 2064 2156 2062 1997 1996 2502 3861 1998 1996 2878 2791 1998 6730 2791 1997 2035 2477 1012 2027 2024 1996 3521 11153 1012 2027 2079 2025 5223 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] love this . . . and her . what a relief that , at last . . . long , long , long last . . . what women have endured is being taken seriously . thank you , nell . . . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] love this . . . and her . what a relief that , at last . . . long , long , long last . . . what women have endured is being taken seriously . thank you , nell . . . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2293 2023 1012 1012 1012 1998 2014 1012 2054 1037 4335 2008 1010 2012 2197 1012 1012 1012 2146 1010 2146 1010 2146 2197 1012 1012 1012 2054 2308 2031 16753 2003 2108 2579 5667 1012 4067 2017 1010 20970 1012 1012 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2293 2023 1012 1012 1012 1998 2014 1012 2054 1037 4335 2008 1010 2012 2197 1012 1012 1012 2146 1010 2146 1010 2146 2197 1012 1012 1012 2054 2308 2031 16753 2003 2108 2579 5667 1012 4067 2017 1010 20970 1012 1012 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] ` ` there is an international community that occasionally can be led by the only real power left in the world , and that ' s the united states , when it suits our interests and when we can get others to go along . ` ` ' ' i confess i had no desire to die in a southeast asian rice paddy . i considered the war in vietnam already lost . ` ` ' ' you do n ' t need to spend tens of millions of dollars on political consultants to tell you what you think when you already know what you think . ` ` ' ' do n ' t get me wrong : i would love to be president . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] ` ` there is an international community that occasionally can be led by the only real power left in the world , and that ' s the united states , when it suits our interests and when we can get others to go along . ` ` ' ' i confess i had no desire to die in a southeast asian rice paddy . i considered the war in vietnam already lost . ` ` ' ' you do n ' t need to spend tens of millions of dollars on political consultants to tell you what you think when you already know what you think . ` ` ' ' do n ' t get me wrong : i would love to be president . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1036 1036 2045 2003 2019 2248 2451 2008 5681 2064 2022 2419 2011 1996 2069 2613 2373 2187 1999 1996 2088 1010 1998 2008 1005 1055 1996 2142 2163 1010 2043 2009 11072 2256 5426 1998 2043 2057 2064 2131 2500 2000 2175 2247 1012 1036 1036 1005 1005 1045 18766 1045 2018 2053 4792 2000 3280 1999 1037 4643 4004 5785 16063 1012 1045 2641 1996 2162 1999 5148 2525 2439 1012 1036 1036 1005 1005 2017 2079 1050 1005 1056 2342 2000 5247 15295 1997 8817 1997 6363 2006 2576 22283 2000 2425 2017 2054 2017 2228 2043 2017 2525 2113 2054 2017 2228 1012 1036 1036 1005 1005 2079 1050 1005 1056 2131 2033 3308 1024 1045 2052 2293 2000 2022 2343 1012 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1036 1036 2045 2003 2019 2248 2451 2008 5681 2064 2022 2419 2011 1996 2069 2613 2373 2187 1999 1996 2088 1010 1998 2008 1005 1055 1996 2142 2163 1010 2043 2009 11072 2256 5426 1998 2043 2057 2064 2131 2500 2000 2175 2247 1012 1036 1036 1005 1005 1045 18766 1045 2018 2053 4792 2000 3280 1999 1037 4643 4004 5785 16063 1012 1045 2641 1996 2162 1999 5148 2525 2439 1012 1036 1036 1005 1005 2017 2079 1050 1005 1056 2342 2000 5247 15295 1997 8817 1997 6363 2006 2576 22283 2000 2425 2017 2054 2017 2228 2043 2017 2525 2113 2054 2017 2228 1012 1036 1036 1005 1005 2079 1050 1005 1056 2131 2033 3308 1024 1045 2052 2293 2000 2022 2343 1012 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 40000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 40000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 40000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 40000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 40000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 40000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 5000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] bart ##olo ` ` is there any evidence ' ' yes . hack ##s have been demonstrated possible by experiment , multiple times by multiple independent investigators . there have been counts that just do n ' t make sense , and strongly suggest hacking . it could not be checked because there was no record . would big money attempt to buy power ? where do bears do it ? [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] bart ##olo ` ` is there any evidence ' ' yes . hack ##s have been demonstrated possible by experiment , multiple times by multiple independent investigators . there have been counts that just do n ' t make sense , and strongly suggest hacking . it could not be checked because there was no record . would big money attempt to buy power ? where do bears do it ? [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 12075 12898 1036 1036 2003 2045 2151 3350 1005 1005 2748 1012 20578 2015 2031 2042 7645 2825 2011 7551 1010 3674 2335 2011 3674 2981 14766 1012 2045 2031 2042 9294 2008 2074 2079 1050 1005 1056 2191 3168 1010 1998 6118 6592 23707 1012 2009 2071 2025 2022 7039 2138 2045 2001 2053 2501 1012 2052 2502 2769 3535 2000 4965 2373 1029 2073 2079 6468 2079 2009 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 12075 12898 1036 1036 2003 2045 2151 3350 1005 1005 2748 1012 20578 2015 2031 2042 7645 2825 2011 7551 1010 3674 2335 2011 3674 2981 14766 1012 2045 2031 2042 9294 2008 2074 2079 1050 1005 1056 2191 3168 1010 1998 6118 6592 23707 1012 2009 2071 2025 2022 7039 2138 2045 2001 2053 2501 1012 2052 2502 2769 3535 2000 4965 2373 1029 2073 2079 6468 2079 2009 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] reagan who did n ' t smoke advertised cigarettes after they were known car ##cino ##gens . this is the go ##p this is america . it will cost our economy big time here in canada but the usa belongs with russia not the western demo ##cr ##acies . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] reagan who did n ' t smoke advertised cigarettes after they were known car ##cino ##gens . this is the go ##p this is america . it will cost our economy big time here in canada but the usa belongs with russia not the western demo ##cr ##acies . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11531 2040 2106 1050 1005 1056 5610 17099 15001 2044 2027 2020 2124 2482 21081 21230 1012 2023 2003 1996 2175 2361 2023 2003 2637 1012 2009 2097 3465 2256 4610 2502 2051 2182 1999 2710 2021 1996 3915 7460 2007 3607 2025 1996 2530 9703 26775 20499 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11531 2040 2106 1050 1005 1056 5610 17099 15001 2044 2027 2020 2124 2482 21081 21230 1012 2023 2003 1996 2175 2361 2023 2003 2637 1012 2009 2097 3465 2256 4610 2502 2051 2182 1999 2710 2021 1996 3915 7460 2007 3607 2025 1996 2530 9703 26775 20499 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] congress ' time to ` ` wake up soon ' ' happened long ago . they did n ' t . they , in fact , will be remembered by history as fe ##ckle ##ss and coco ##ns ##pi ##rator ##ial by their complete lack of even comment during this time in the u . s . ' s history . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] congress ' time to ` ` wake up soon ' ' happened long ago . they did n ' t . they , in fact , will be remembered by history as fe ##ckle ##ss and coco ##ns ##pi ##rator ##ial by their complete lack of even comment during this time in the u . s . ' s history . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3519 1005 2051 2000 1036 1036 5256 2039 2574 1005 1005 3047 2146 3283 1012 2027 2106 1050 1005 1056 1012 2027 1010 1999 2755 1010 2097 2022 4622 2011 2381 2004 10768 19250 4757 1998 25033 3619 8197 16259 4818 2011 2037 3143 3768 1997 2130 7615 2076 2023 2051 1999 1996 1057 1012 1055 1012 1005 1055 2381 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3519 1005 2051 2000 1036 1036 5256 2039 2574 1005 1005 3047 2146 3283 1012 2027 2106 1050 1005 1056 1012 2027 1010 1999 2755 1010 2097 2022 4622 2011 2381 2004 10768 19250 4757 1998 25033 3619 8197 16259 4818 2011 2037 3143 3768 1997 2130 7615 2076 2023 2051 1999 1996 1057 1012 1055 1012 1005 1055 2381 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] as long as republicans in congress allow trump to run the country as his own personal video game that can del ##ete people with the flick of a finger on the keyboard , we ' re in trouble . so obvious that trump is attempting to th ##wart mueller ' s investigation by imp ##ug ##ning the credibility of mcc ##abe and come ##y . donald trump aka dennis the menace . who ' s running the country while trump watches cable news , t ##wee ##ts , and golf ##s ? his sole mission is to bath in the glow of media attention , and anybody who dare ##s stain his image is toast . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] as long as republicans in congress allow trump to run the country as his own personal video game that can del ##ete people with the flick of a finger on the keyboard , we ' re in trouble . so obvious that trump is attempting to th ##wart mueller ' s investigation by imp ##ug ##ning the credibility of mcc ##abe and come ##y . donald trump aka dennis the menace . who ' s running the country while trump watches cable news , t ##wee ##ts , and golf ##s ? his sole mission is to bath in the glow of media attention , and anybody who dare ##s stain his image is toast . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2004 2146 2004 10643 1999 3519 3499 8398 2000 2448 1996 2406 2004 2010 2219 3167 2678 2208 2008 2064 3972 12870 2111 2007 1996 17312 1997 1037 4344 2006 1996 9019 1010 2057 1005 2128 1999 4390 1012 2061 5793 2008 8398 2003 7161 2000 16215 18367 26774 1005 1055 4812 2011 17727 15916 5582 1996 21553 1997 23680 16336 1998 2272 2100 1012 6221 8398 9875 6877 1996 19854 1012 2040 1005 1055 2770 1996 2406 2096 8398 12197 5830 2739 1010 1056 28394 3215 1010 1998 5439 2015 1029 2010 7082 3260 2003 2000 7198 1999 1996 8652 1997 2865 3086 1010 1998 10334 2040 8108 2015 21101 2010 3746 2003 15174 1012 102 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2004 2146 2004 10643 1999 3519 3499 8398 2000 2448 1996 2406 2004 2010 2219 3167 2678 2208 2008 2064 3972 12870 2111 2007 1996 17312 1997 1037 4344 2006 1996 9019 1010 2057 1005 2128 1999 4390 1012 2061 5793 2008 8398 2003 7161 2000 16215 18367 26774 1005 1055 4812 2011 17727 15916 5582 1996 21553 1997 23680 16336 1998 2272 2100 1012 6221 8398 9875 6877 1996 19854 1012 2040 1005 1055 2770 1996 2406 2096 8398 12197 5830 2739 1010 1056 28394 3215 1010 1998 5439 2015 1029 2010 7082 3260 2003 2000 7198 1999 1996 8652 1997 2865 3086 1010 1998 10334 2040 8108 2015 21101 2010 3746 2003 15174 1012 102 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] wow . i definitely wo n ' t be watching this show . it seems ms . barr , like so many other trump supporters , refuses to believe facts about mr . trump . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] wow . i definitely wo n ' t be watching this show . it seems ms . barr , like so many other trump supporters , refuses to believe facts about mr . trump . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 10166 1012 1045 5791 24185 1050 1005 1056 2022 3666 2023 2265 1012 2009 3849 5796 1012 19820 1010 2066 2061 2116 2060 8398 6793 1010 10220 2000 2903 8866 2055 2720 1012 8398 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 10166 1012 1045 5791 24185 1050 1005 1056 2022 3666 2023 2265 1012 2009 3849 5796 1012 19820 1010 2066 2061 2116 2060 8398 6793 1010 10220 2000 2903 8866 2055 2720 1012 8398 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6uaC_TjCz8n",
        "colab_type": "text"
      },
      "source": [
        "## Définition d'un modèle de classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H3FdYvtmX81",
        "colab_type": "text"
      },
      "source": [
        "Maintenant que nos commentaires sont correctement formatés, on peut construire le modèle de classification qui va être exploité."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrnoWLSRqJtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uQiTiDKqM-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5P3CSBsC3iP",
        "colab_type": "text"
      },
      "source": [
        "## Paramètres du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-URcmW-qPC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 10.0\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7EFZf4FqQ9c",
        "colab_type": "code",
        "outputId": "8e6d5959-9a4c-4721-f0ee-b2deb2f170e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute # train and warmup steps from batch size\n",
        "#num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_train_steps = 500\n",
        "#num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "num_warmup_steps = 50\n",
        "\n",
        "print(\"steps par epoque :\", num_train_steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "steps par epoque : 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwMvJWuvC_gq",
        "colab_type": "text"
      },
      "source": [
        "## Création du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdtEW478qVLQ",
        "colab_type": "code",
        "outputId": "bf71a001-26c9-48de-884b-b6aa04698957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpglvnv_x_\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpglvnv_x_\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpglvnv_x_', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f922fdb25f8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpglvnv_x_', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f922fdb25f8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f8e9rpqCCP-",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "On entraîne notre modèle de BERT sur df_TRAIN_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkOHrnhFmkqz",
        "colab_type": "text"
      },
      "source": [
        "On crée ensuite une fonction qui prend en entrée notre ensemble d'apprentissage (train_features) et qui produit un générateur. Il s'agit d'une fonction standard pour pouvoir exploiter les estimateurs de TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqNkRQiTqXII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3aFiKHUmp_L",
        "colab_type": "text"
      },
      "source": [
        "On entraîne notre modèle :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZbRYS8GqZAa",
        "colab_type": "code",
        "outputId": "cc66130b-e53c-41c0-cec1-4f8f1c8e756a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# !!! Très long à exécuter (environ 4h)\n",
        "\n",
        "# Training \n",
        "\n",
        "print(f'Beginning Training!')\n",
        "print('\\n')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print('\\n')\n",
        "print(\"Training took time : \", datetime.now() - current_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-ca03218f28a6>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-ca03218f28a6>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:117: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:117: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.6432018, step = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.6432018, step = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 20 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 20 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 29 vs previous value: 29. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 29 vs previous value: 29. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 31 vs previous value: 31. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 31 vs previous value: 31. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 33 vs previous value: 33. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 33 vs previous value: 33. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 35 vs previous value: 35. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 35 vs previous value: 35. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 40 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 40 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 60 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 60 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 80 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 80 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 92 vs previous value: 92. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 92 vs previous value: 92. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.03275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.03275\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.4900871, step = 101 (3053.486 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.4900871, step = 101 (3053.486 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 120 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 140 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 140 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 160 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 160 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 182 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 182 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0337555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0337555\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.38584125, step = 201 (2962.440 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.38584125, step = 201 (2962.440 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 204 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 204 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 227 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 227 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 248 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 248 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 269 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 269 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 290 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 290 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0350358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0350358\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.36795712, step = 301 (2854.235 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.36795712, step = 301 (2854.235 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 311 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 311 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 332 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 332 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 353 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 353 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 374 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 374 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 396 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 396 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0346269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0346269\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.20632645, step = 401 (2887.917 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.20632645, step = 401 (2887.917 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 418 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 418 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 439 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 439 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 460 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 460 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 481 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 481 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 500 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 500 into /tmp/tmpglvnv_x_/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.27464232.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.27464232.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training took time :  4:05:13.012603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG7BkWwQBzVy",
        "colab_type": "text"
      },
      "source": [
        "## Testing\n",
        "\n",
        "On teste sur df_TEST_Trump_2 notre modèle de BERT entraîné."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duXrz7aqmyTU",
        "colab_type": "text"
      },
      "source": [
        "On évalue ensuite le modèle sur l'ensemble de test :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itPgzmXiqwiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcBZ086wqym6",
        "colab_type": "code",
        "outputId": "8f65af35-72d1-408c-8e82-12177220ef3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "# !!! Assez long à exécuter (environ 30 min)\n",
        "\n",
        "current_time = datetime.now()\n",
        "estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "print('\\n')\n",
        "print(\"Testing took time : \", datetime.now() - current_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-04-12T10:50:27Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-04-12T10:50:27Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpglvnv_x_/model.ckpt-500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpglvnv_x_/model.ckpt-500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-04-12-11:17:42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-04-12-11:17:42\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 500: auc = 0.84613055, eval_accuracy = 0.853, f1_score = 0.8189209, false_negatives = 397.0, false_positives = 338.0, global_step = 500, loss = 0.3283016, precision = 0.831, recall = 0.807188, true_negatives = 2603.0, true_positives = 1662.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 500: auc = 0.84613055, eval_accuracy = 0.853, f1_score = 0.8189209, false_negatives = 397.0, false_positives = 338.0, global_step = 500, loss = 0.3283016, precision = 0.831, recall = 0.807188, true_negatives = 2603.0, true_positives = 1662.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: /tmp/tmpglvnv_x_/model.ckpt-500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: /tmp/tmpglvnv_x_/model.ckpt-500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Testing took time :  0:27:29.455522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpMAVZjVHrE3",
        "colab_type": "text"
      },
      "source": [
        "Résultats obtenus : Saving dict for global step 500: auc = 0.84613055, eval_accuracy = 0.853, f1_score = 0.8189209, false_negatives = 397.0, false_positives = 338.0, global_step = 500, loss = 0.3283016, precision = 0.831, recall = 0.807188, true_negatives = 2603.0, true_positives = 1662.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fof_ofoIm599",
        "colab_type": "text"
      },
      "source": [
        "La précision sur notre ensemble de test est de 85% ce qui est une bonne performance !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF9VgHk3ONAx",
        "colab_type": "code",
        "outputId": "68ebe108-cc81-4f57-df4b-ed3af8c830bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# Matrice de Confusion\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = {'y_Actual':    [1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0],\n",
        "        'y_Predicted': [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
        "        }\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "\n",
        "# On remplace à la main par nos vraies valeurs issues de BERT sur nos Tests :\n",
        "confusion_matrix[0][0] = 2603 # True_Negatives\n",
        "confusion_matrix[1][1] = 1662 # True_Positives\n",
        "confusion_matrix[0][1] = 397 # False_Negatives\n",
        "confusion_matrix[1][0] = 338 # False_Positives\n",
        "\n",
        "sn.heatmap(confusion_matrix, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh5tN_uDYynp",
        "colab_type": "text"
      },
      "source": [
        "#  Évaluation\n",
        "\n",
        "On veut comparer notre modèle à d'autres modèles (plus simples en géénral) pour rendre compte de ses améliorations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_op6-oDwY2z-",
        "colab_type": "text"
      },
      "source": [
        "## Qualitative - Prédictions\n",
        "\n",
        "On prédit le label sur des phrases et on juge nous-même si le label correspond bien"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHCPNBLlnJLG",
        "colab_type": "text"
      },
      "source": [
        "On réalise ensuite une fonction afin de pouvoir faire des prédictions sur d'autres commentaires "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jETsE3vfq0bS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getPrediction(in_sentences):\n",
        "  labels = [\"Negative\", \"Positive\"]\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xo8EgrCyti2",
        "colab_type": "text"
      },
      "source": [
        "On peut tester n'importe quelle phrase en anglais en la mettant dans la liste suivante :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z8UxQnkq3RL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_sentences = [\n",
        "  \"That movie was absolutely awful\",\n",
        "  \"The acting was a bit lacking\",\n",
        "  \"The film was creative and surprising\",\n",
        "  \"Absolutely fantastic!\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRIoD5ojq7MV",
        "colab_type": "code",
        "outputId": "e3499846-800b-42d6-b6d6-371c198c0849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predictions = getPrediction(pred_sentences)\n",
        "predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] that movie was absolutely awful [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] that movie was absolutely awful [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2008 3185 2001 7078 9643 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2008 3185 2001 7078 9643 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the acting was a bit lacking [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the acting was a bit lacking [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 3772 2001 1037 2978 11158 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 3772 2001 1037 2978 11158 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the film was creative and surprising [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the film was creative and surprising [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 2143 2001 5541 1998 11341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 2143 2001 5541 1998 11341 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] absolutely fantastic ! [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] absolutely fantastic ! [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 7078 10392 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 7078 10392 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpglvnv_x_/model.ckpt-500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpglvnv_x_/model.ckpt-500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('That movie was absolutely awful',\n",
              "  array([-0.01318545, -4.335228  ], dtype=float32),\n",
              "  'Negative'),\n",
              " ('The acting was a bit lacking',\n",
              "  array([-0.03777353, -3.2949746 ], dtype=float32),\n",
              "  'Negative'),\n",
              " ('The film was creative and surprising',\n",
              "  array([-0.69802773, -0.68829036], dtype=float32),\n",
              "  'Positive'),\n",
              " ('Absolutely fantastic!',\n",
              "  array([-4.8109527 , -0.00817347], dtype=float32),\n",
              "  'Positive')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St5dNLI5Y6t6",
        "colab_type": "text"
      },
      "source": [
        "## Quantitative - BING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI09S-BvhhK_",
        "colab_type": "text"
      },
      "source": [
        "On va comparer nos résultats avec un modèle très simple basé sur le lexique BING."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl0FVwZRkYXe",
        "colab_type": "text"
      },
      "source": [
        "Explications BING : https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T5STmXkdrat",
        "colab_type": "code",
        "outputId": "81d729c1-7a57-4227-daa7-b15a1737509c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "# Lexique BING\n",
        "# Importation des deux fichiers NEGATIFS et POSITIFS, contennant les listes des mots connotés comme négatifs et positifs\n",
        "\n",
        "!wget -O negative-words.txt https://drive.google.com/uc?id=1efaGEdl-lCeTAwrN6NgwWIRZmDqyA5dm\n",
        "!wget -O positive-words.txt https://drive.google.com/uc?id=1L-emKlpNgJ6IQE5RriByjTOva2F2Birl\n",
        "\n",
        "words_neg = pd.read_table('/content/negative-words.txt', encoding='latin-1')\n",
        "words_pos = pd.read_table('/content/positive-words.txt', encoding='latin-1')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-12 11:27:29--  https://drive.google.com/uc?id=1efaGEdl-lCeTAwrN6NgwWIRZmDqyA5dm\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.24.138, 74.125.24.100, 74.125.24.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.24.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0c-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/c9hmgpn1bor44oida84me086geme248c/1586690775000/08369696792954202122/*/1efaGEdl-lCeTAwrN6NgwWIRZmDqyA5dm [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-04-12 11:27:29--  https://doc-0c-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/c9hmgpn1bor44oida84me086geme248c/1586690775000/08369696792954202122/*/1efaGEdl-lCeTAwrN6NgwWIRZmDqyA5dm\n",
            "Resolving doc-0c-94-docs.googleusercontent.com (doc-0c-94-docs.googleusercontent.com)... 172.217.194.132, 2404:6800:4003:c04::84\n",
            "Connecting to doc-0c-94-docs.googleusercontent.com (doc-0c-94-docs.googleusercontent.com)|172.217.194.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49546 (48K) [text/plain]\n",
            "Saving to: ‘negative-words.txt’\n",
            "\n",
            "negative-words.txt  100%[===================>]  48.38K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-12 11:27:30 (153 MB/s) - ‘negative-words.txt’ saved [49546/49546]\n",
            "\n",
            "--2020-04-12 11:27:33--  https://drive.google.com/uc?id=1L-emKlpNgJ6IQE5RriByjTOva2F2Birl\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.24.138, 74.125.24.100, 74.125.24.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.24.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0s-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bl8ctv3iq5d0lmbedqe8ahevlteaol34/1586690850000/08369696792954202122/*/1L-emKlpNgJ6IQE5RriByjTOva2F2Birl [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-04-12 11:27:33--  https://doc-0s-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bl8ctv3iq5d0lmbedqe8ahevlteaol34/1586690850000/08369696792954202122/*/1L-emKlpNgJ6IQE5RriByjTOva2F2Birl\n",
            "Resolving doc-0s-94-docs.googleusercontent.com (doc-0s-94-docs.googleusercontent.com)... 172.217.194.132, 2404:6800:4003:c04::84\n",
            "Connecting to doc-0s-94-docs.googleusercontent.com (doc-0s-94-docs.googleusercontent.com)|172.217.194.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21104 (21K) [text/plain]\n",
            "Saving to: ‘positive-words.txt’\n",
            "\n",
            "positive-words.txt  100%[===================>]  20.61K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-12 11:27:34 (70.7 MB/s) - ‘positive-words.txt’ saved [21104/21104]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMpvTmlvhspc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fonction appliquant le lexique BING\n",
        "\n",
        "def BING(texte):\n",
        "\n",
        "  from functools import reduce\n",
        "  from operator import add\n",
        "  from spacy.tokenizer import Tokenizer\n",
        "  from spacy.lang.en import English\n",
        "  nlp = English()\n",
        "\n",
        "  ### Tokenization\n",
        "\n",
        "  # Instanciating the tokenizer\n",
        "  tokenizer = Tokenizer(nlp.vocab)\n",
        "\n",
        "  # Repeating the earlier vocabulary count\n",
        "  arr = texte.drop_duplicates().apply(lambda x: [w.text for w in tokenizer(x)]).array\n",
        "  arr = reduce(add, arr)\n",
        "  print(\"Vocabulary size with Spacy's tokenizer: {}\".format(len(set(arr))))\n",
        "  print('\\n')\n",
        "\n",
        "  # Inspecting a tokenization sample\n",
        "  tokenization_sample = texte.drop_duplicates().apply(lambda x: \n",
        "                                              [w.text for w in tokenizer(x)])\n",
        "  print(\"Tokenization sample:\\n {}\".format(tokenization_sample))\n",
        "\n",
        "\n",
        "  ### BING \n",
        "\n",
        "  scores = []\n",
        "  for i in range(tokenization_sample.shape[0]) :\n",
        "    score = 0\n",
        "    for j in range(len(tokenization_sample.iloc[i])) :\n",
        "      if str(tokenization_sample.iloc[i][j]) in str(words_neg) :\n",
        "        score = score-1\n",
        "      if str(tokenization_sample.iloc[i][j]) in str(words_pos) :\n",
        "        score = score+1\n",
        "    scores.append(score)\n",
        "  \n",
        "\n",
        "  # 2 labels\n",
        "  Lab_BING = []\n",
        "  Lab_BING = [1 if score > 0  # 'positive'\n",
        "                          else 0 # 'negative'\n",
        "                                  for score in scores]\n",
        "\n",
        "\n",
        "  #df_BING = pd.DataFrame(Lab_BING)\n",
        "  #df_BING.columns = ['label_BING']\n",
        "  return(Lab_BING)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5H7T-FFJtQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# On importe à nouveau le Dataframe car l'environnement l'a peut être supprimé pendant l'apprentissage de BERT\n",
        "df_TEST_Trump_2 = pd.read_csv('/content/df_TEST_Trump_2.csv', delimiter=';')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4MYiQC5jDHR",
        "colab_type": "code",
        "outputId": "a1eeb94d-646f-4368-d4db-010a6a0ce4a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# !!! Très long à exécuter (environ 1h)\n",
        "\n",
        "# Application de la fonction BING pour labelliser\n",
        "\n",
        "current_time = datetime.now()\n",
        "\n",
        "BING_TEST_Trump = BING(df_TEST_Trump_2.text)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Testing took time : \", datetime.now() - current_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size with Spacy's tokenizer: 22741\n",
            "\n",
            "\n",
            "Tokenization sample:\n",
            " 0       [ , bartolo,  , ``, is, there, any, evidence, ...\n",
            "1       [ , reagan, who, did, n't, smoke, advertised, ...\n",
            "2       [ , congress, ', time, to, ``, wake, up, soon,...\n",
            "3       [ , as, long, as, republicans, in, congress, a...\n",
            "4       [ , wow, ., i, definitely, wo, n't, be, watchi...\n",
            "                              ...                        \n",
            "4995    [ , the, article, reads, as, thought, the, va,...\n",
            "4996    [ , trump, is, simply, repulsive, ., he, is, e...\n",
            "4997    [ , this, is, a, good, move, ., if, steel, man...\n",
            "4998    [ , where, is, the, reasoned, and, rational, u...\n",
            "4999    [ , unless, and, until, we, can, see, donald, ...\n",
            "Name: text, Length: 4999, dtype: object\n",
            "\n",
            "\n",
            "Testing took time :  0:54:34.830541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut07s4rY7D_b",
        "colab_type": "text"
      },
      "source": [
        "La cellule suivante indique qu'il y a un soucis de dimensions ici. Cependant, nous n'avons pas réussi à résoudre ce soucis mineur : le dernier commentaire n'est pas labellisé car la taille du \"tokenization_sample\" est 4999 au lieu de 5000 (indices de 0 à 4999)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpHfyBHmp1BB",
        "colab_type": "code",
        "outputId": "58403cce-9b10-49fe-89e6-26720eb3774b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Nombre de labels avec le lexique AFINN :', len(Labels_Test_Trump_2))\n",
        "print('Nombre de labels avec le lexique BING :', len(BING_TEST_Trump))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nombre de labels avec le lexique AFINN : 5000\n",
            "Nombre de labels avec le lexique BING : 4999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW8T6WuMY7-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creation d'un CSV pour pouvoir relancer la suite sans to run si l'environnement a été reset\n",
        "\n",
        "df_BING = pd.DataFrame(BING_TEST_Trump)\n",
        "df_BING.columns = ['label_BING']\n",
        "df_BING.to_csv('BING_TEST_Trump.csv', sep=';')\n",
        "\n",
        "# dans les fichiers a gauche, on peut \"actualiser\" puis \"télécharger\" les bases "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe860eASET85",
        "colab_type": "code",
        "outputId": "06f9887f-2148-4471-eaab-983f5e76f327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Précision de BING\n",
        "\n",
        "nbre = 0\n",
        "for i in range(len(BING_TEST_Trump)):\n",
        "  if BING_TEST_Trump[i] == Labels_Test_Trump_2[i]:\n",
        "    nbre = nbre + 1\n",
        "\n",
        "precision_BING = nbre/len(BING_TEST_Trump)\n",
        "print('BING a une précision de ', precision_BING)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BING a une précision de  0.5577115423084616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYFACY6oLryy",
        "colab_type": "code",
        "outputId": "f24417a6-9151-40bd-8848-fd2952bc5cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# Matrice de Confusion pour comparer BING aux vrais labels (issus de AFINN)\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = {'y_Actual': Labels_Test_Trump_2[0:4999], # on tronque cette liste pour faire correspondre les dimensions\n",
        "        'y_Predicted': BING_TEST_Trump\n",
        "        }\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "\n",
        "sn.heatmap(confusion_matrix, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RezPAYqxb_j",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lF5fG9sxeTC",
        "colab_type": "text"
      },
      "source": [
        "On constate que notre modèle basé sur le BERT du Github fournit de bons résultats qualitatifs. En effet, nos prédictions sur de nouvelles phrases semblent cohérentes avec l'interprétation humaine qu'on pourrait en faire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFBg8fbDxubc",
        "colab_type": "text"
      },
      "source": [
        "De plus, notre modèle est plus précis qu'un modèle plus simple (classification avec BING) donc il correpond à une meilleure option de résolution de notre problème de classification. La matrice de confusion semble d'ailleurs assez bonne car il y a peu de faux négatifs ou de faux positifs, ce qui est un critère important pour un outil de classification binaire de sentiments."
      ]
    }
  ]
}